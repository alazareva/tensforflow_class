Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
observation_input (InputLayer)  [(None, 10, 97, 96)] 0                                            
__________________________________________________________________________________________________
permute (Permute)               (None, 97, 96, 10)   0           observation_input[0][0]          
__________________________________________________________________________________________________
cropping2d (Cropping2D)         (None, 96, 96, 10)   0           permute[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 23, 23, 32)   20512       cropping2d[0][0]                 
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 10, 10, 32)   16416       conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 8, 8, 32)     9248        conv2d_1[0][0]                   
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 1, 96, 10)    0           permute[0][0]                    
__________________________________________________________________________________________________
flatten (Flatten)               (None, 2048)         0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1, 96, 256)   2816        cropping2d_1[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          1049088     flatten[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 24576)        0           dense_1[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 25088)        0           dense[0][0]                      
                                                                 flatten_1[0][0]                  
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 5)            125445      concatenate[0][0]                
==================================================================================================
Total params: 1,223,525
Trainable params: 1,223,525
Non-trainable params: 0

   1000/500000: episode: 1, duration: 18.817s, episode steps: 1000, steps per second:  53, episode reward: -31.034, mean reward: -0.031 [-0.100,  7.563], mean action: 2.792 [0.000, 4.000],  loss: --, mae: --, mean_q: --
Track generation: 1235..1548 -> 313-tiles track
   2000/500000: episode: 2, duration: 42.167s, episode steps: 1000, steps per second:  24, episode reward: -32.692, mean reward: -0.033 [-0.100,  6.310], mean action: 2.443 [0.000, 4.000],  loss: 1.851359, mae: 14.700382, mean_q: 19.962730
Track generation: 1087..1370 -> 283-tiles track
   3000/500000: episode: 3, duration: 40.596s, episode steps: 1000, steps per second:  25, episode reward: -7.801, mean reward: -0.008 [-0.100,  6.992], mean action: 2.114 [0.000, 4.000],  loss: 0.782182, mae: 13.903665, mean_q: 18.882860
Track generation: 1210..1517 -> 307-tiles track
   4000/500000: episode: 4, duration: 41.846s, episode steps: 1000, steps per second:  24, episode reward: -67.320, mean reward: -0.067 [-0.100,  6.436], mean action: 2.122 [0.000, 4.000],  loss: 0.790127, mae: 13.986431, mean_q: 18.985005
Track generation: 955..1199 -> 244-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1147..1444 -> 297-tiles track
   5000/500000: episode: 5, duration: 41.740s, episode steps: 1000, steps per second:  24, episode reward: -72.973, mean reward: -0.073 [-0.100,  6.657], mean action: 2.162 [0.000, 4.000],  loss: 0.684691, mae: 14.711423, mean_q: 19.587807
Track generation: 1108..1396 -> 288-tiles track
   6000/500000: episode: 6, duration: 41.132s, episode steps: 1000, steps per second:  24, episode reward: -23.345, mean reward: -0.023 [-0.100,  6.869], mean action: 2.030 [0.000, 4.000],  loss: 0.692676, mae: 14.626169, mean_q: 19.308553
Track generation: 1039..1303 -> 264-tiles track
   7000/500000: episode: 7, duration: 40.156s, episode steps: 1000, steps per second:  25, episode reward: 10.266, mean reward:  0.010 [-0.100,  7.505], mean action: 1.752 [0.000, 4.000],  loss: 0.680865, mae: 14.842141, mean_q: 19.534250
Track generation: 1123..1408 -> 285-tiles track
   8000/500000: episode: 8, duration: 40.823s, episode steps: 1000, steps per second:  24, episode reward: -29.577, mean reward: -0.030 [-0.100,  6.942], mean action: 2.077 [0.000, 4.000],  loss: 0.774314, mae: 15.107587, mean_q: 19.802045
Track generation: 1143..1433 -> 290-tiles track
   9000/500000: episode: 9, duration: 40.715s, episode steps: 1000, steps per second:  25, episode reward:  0.346, mean reward:  0.000 [-0.100,  6.820], mean action: 1.692 [0.000, 4.000],  loss: 0.807274, mae: 14.664935, mean_q: 19.292418
Track generation: 1116..1405 -> 289-tiles track
  10000/500000: episode: 10, duration: 41.621s, episode steps: 1000, steps per second:  24, episode reward: -65.278, mean reward: -0.065 [-0.100,  6.844], mean action: 1.189 [0.000, 4.000],  loss: 0.723153, mae: 14.420689, mean_q: 19.001699
Track generation: 1082..1356 -> 274-tiles track
  11000/500000: episode: 11, duration: 40.744s, episode steps: 1000, steps per second:  25, episode reward: -56.044, mean reward: -0.056 [-0.100,  7.226], mean action: 2.079 [0.000, 4.000],  loss: 0.619129, mae: 15.536144, mean_q: 20.172170
Track generation: 1063..1333 -> 270-tiles track
  12000/500000: episode: 12, duration: 40.418s, episode steps: 1000, steps per second:  25, episode reward: -44.238, mean reward: -0.044 [-0.100,  7.335], mean action: 2.621 [0.000, 4.000],  loss: 0.516974, mae: 15.449316, mean_q: 19.934638
Track generation: 1363..1708 -> 345-tiles track
  13000/500000: episode: 13, duration: 42.977s, episode steps: 1000, steps per second:  23, episode reward: -21.512, mean reward: -0.022 [-0.100,  5.714], mean action: 1.839 [0.000, 4.000],  loss: 0.407049, mae: 15.356966, mean_q: 19.774317
Track generation: 1143..1433 -> 290-tiles track
  14000/500000: episode: 14, duration: 40.390s, episode steps: 1000, steps per second:  25, episode reward: -44.637, mean reward: -0.045 [-0.100,  6.820], mean action: 1.422 [0.000, 4.000],  loss: 0.366235, mae: 15.803996, mean_q: 20.303025
Track generation: 1105..1391 -> 286-tiles track
  15000/500000: episode: 15, duration: 40.870s, episode steps: 1000, steps per second:  24, episode reward: -29.825, mean reward: -0.030 [-0.100,  6.918], mean action: 2.614 [0.000, 4.000],  loss: 0.365888, mae: 15.610866, mean_q: 20.006076
Track generation: 1204..1509 -> 305-tiles track
  16000/500000: episode: 16, duration: 41.828s, episode steps: 1000, steps per second:  24, episode reward: -44.079, mean reward: -0.044 [-0.100,  6.479], mean action: 2.105 [0.000, 4.000],  loss: 0.373377, mae: 15.771627, mean_q: 20.208640
Track generation: 1108..1389 -> 281-tiles track
  17000/500000: episode: 17, duration: 41.109s, episode steps: 1000, steps per second:  24, episode reward: -17.857, mean reward: -0.018 [-0.100,  7.043], mean action: 2.019 [0.000, 4.000],  loss: 0.389080, mae: 15.782382, mean_q: 20.225106
Track generation: 1088..1368 -> 280-tiles track
  18000/500000: episode: 18, duration: 41.133s, episode steps: 1000, steps per second:  24, episode reward: -67.742, mean reward: -0.068 [-0.100,  7.068], mean action: 2.084 [0.000, 4.000],  loss: 0.376464, mae: 15.625075, mean_q: 20.002816
Track generation: 1116..1399 -> 283-tiles track
  18829/500000: episode: 19, duration: 34.411s, episode steps: 829, steps per second:  24, episode reward: -147.339, mean reward: -0.178 [-100.000,  6.992], mean action: 2.392 [0.000, 4.000],  loss: 0.326883, mae: 15.841458, mean_q: 20.224232
Track generation: 1098..1383 -> 285-tiles track
  19829/500000: episode: 20, duration: 40.638s, episode steps: 1000, steps per second:  25, episode reward: -36.620, mean reward: -0.037 [-0.100,  6.942], mean action: 2.374 [0.000, 4.000],  loss: 0.372862, mae: 15.678393, mean_q: 20.038932
Track generation: 1149..1409 -> 260-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 984..1237 -> 253-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1138..1426 -> 288-tiles track
  20829/500000: episode: 21, duration: 40.876s, episode steps: 1000, steps per second:  24, episode reward: -68.641, mean reward: -0.069 [-0.100,  6.869], mean action: 2.322 [0.000, 4.000],  loss: 0.324579, mae: 15.783316, mean_q: 20.109499
Track generation: 1108..1389 -> 281-tiles track
  21829/500000: episode: 22, duration: 40.548s, episode steps: 1000, steps per second:  25, episode reward: -71.429, mean reward: -0.071 [-0.100,  7.043], mean action: 2.303 [0.000, 4.000],  loss: 0.279346, mae: 15.827013, mean_q: 20.112195
Track generation: 1144..1437 -> 293-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1071..1343 -> 272-tiles track
  22829/500000: episode: 23, duration: 40.728s, episode steps: 1000, steps per second:  25, episode reward: -44.649, mean reward: -0.045 [-0.100,  7.280], mean action: 1.347 [0.000, 4.000],  loss: 0.222345, mae: 15.784249, mean_q: 20.067319
Track generation: 1056..1324 -> 268-tiles track
  23829/500000: episode: 24, duration: 42.100s, episode steps: 1000, steps per second:  24, episode reward: -62.547, mean reward: -0.063 [-0.100,  7.391], mean action: 1.528 [0.000, 4.000],  loss: 0.250977, mae: 15.698590, mean_q: 19.936486
Track generation: 1135..1423 -> 288-tiles track
  24829/500000: episode: 25, duration: 41.230s, episode steps: 1000, steps per second:  24, episode reward: -58.188, mean reward: -0.058 [-0.100,  6.869], mean action: 2.262 [0.000, 4.000],  loss: 0.254942, mae: 15.729794, mean_q: 19.967067
Track generation: 1245..1561 -> 316-tiles track
  25829/500000: episode: 26, duration: 42.036s, episode steps: 1000, steps per second:  24, episode reward: -58.730, mean reward: -0.059 [-0.100,  6.249], mean action: 2.327 [0.000, 4.000],  loss: 0.250201, mae: 15.889603, mean_q: 20.161542
Track generation: 1105..1386 -> 281-tiles track
  26829/500000: episode: 27, duration: 42.714s, episode steps: 1000, steps per second:  23, episode reward: -25.000, mean reward: -0.025 [-0.100,  7.043], mean action: 2.504 [0.000, 4.000],  loss: 0.284125, mae: 15.884514, mean_q: 20.132604
Track generation: 1247..1563 -> 316-tiles track
  27829/500000: episode: 28, duration: 41.913s, episode steps: 1000, steps per second:  24, episode reward: -52.381, mean reward: -0.052 [-0.100,  6.249], mean action: 3.152 [0.000, 4.000],  loss: 0.219414, mae: 15.958089, mean_q: 20.207426
Track generation: 1194..1497 -> 303-tiles track
  28829/500000: episode: 29, duration: 41.690s, episode steps: 1000, steps per second:  24, episode reward: -33.775, mean reward: -0.034 [-0.100,  6.523], mean action: 1.962 [0.000, 4.000],  loss: 0.255630, mae: 15.837080, mean_q: 20.080194
Track generation: 975..1222 -> 247-tiles track
  29829/500000: episode: 30, duration: 39.394s, episode steps: 1000, steps per second:  25, episode reward: -39.024, mean reward: -0.039 [-0.100,  8.030], mean action: 1.814 [0.000, 4.000],  loss: 0.250527, mae: 15.866637, mean_q: 20.086458
Track generation: 1179..1486 -> 307-tiles track
  30829/500000: episode: 31, duration: 42.173s, episode steps: 1000, steps per second:  24, episode reward: 20.915, mean reward:  0.021 [-0.100,  6.436], mean action: 2.127 [0.000, 4.000],  loss: 0.256862, mae: 15.860344, mean_q: 20.052222
Track generation: 1180..1479 -> 299-tiles track
  31829/500000: episode: 32, duration: 42.022s, episode steps: 1000, steps per second:  24, episode reward: -59.732, mean reward: -0.060 [-0.100,  6.611], mean action: 2.396 [0.000, 4.000],  loss: 0.225203, mae: 16.010434, mean_q: 20.226035
Track generation: 1280..1603 -> 323-tiles track
  32829/500000: episode: 33, duration: 43.173s, episode steps: 1000, steps per second:  23, episode reward: -37.888, mean reward: -0.038 [-0.100,  6.111], mean action: 2.293 [0.000, 4.000],  loss: 0.199173, mae: 15.998751, mean_q: 20.198686
Track generation: 1142..1432 -> 290-tiles track
  33829/500000: episode: 34, duration: 42.537s, episode steps: 1000, steps per second:  24, episode reward: -34.256, mean reward: -0.034 [-0.100,  6.820], mean action: 2.476 [0.000, 4.000],  loss: 0.189799, mae: 16.013389, mean_q: 20.223248
Track generation: 1116..1399 -> 283-tiles track
  34829/500000: episode: 35, duration: 41.158s, episode steps: 1000, steps per second:  24, episode reward: -71.631, mean reward: -0.072 [-0.100,  6.992], mean action: 1.988 [0.000, 4.000],  loss: 0.186477, mae: 15.957660, mean_q: 20.137335
Track generation: 1167..1463 -> 296-tiles track
  35829/500000: episode: 36, duration: 41.354s, episode steps: 1000, steps per second:  24, episode reward: -28.814, mean reward: -0.029 [-0.100,  6.680], mean action: 1.980 [0.000, 4.000],  loss: 0.178442, mae: 15.969056, mean_q: 20.156081
Track generation: 1099..1386 -> 287-tiles track
  36829/500000: episode: 37, duration: 43.575s, episode steps: 1000, steps per second:  23, episode reward: -33.566, mean reward: -0.034 [-0.100,  6.893], mean action: 1.795 [0.000, 4.000],  loss: 0.229910, mae: 15.908317, mean_q: 20.088350
Track generation: 1139..1434 -> 295-tiles track
  37829/500000: episode: 38, duration: 43.035s, episode steps: 1000, steps per second:  23, episode reward:  2.041, mean reward:  0.002 [-0.100,  6.703], mean action: 1.919 [0.000, 4.000],  loss: 0.181432, mae: 15.719774, mean_q: 19.833303
Track generation: 1112..1394 -> 282-tiles track
  38829/500000: episode: 39, duration: 41.920s, episode steps: 1000, steps per second:  24, episode reward: -57.295, mean reward: -0.057 [-0.100,  7.017], mean action: 2.195 [0.000, 4.000],  loss: 0.185274, mae: 15.856376, mean_q: 19.996348
Track generation: 1152..1444 -> 292-tiles track
  39829/500000: episode: 40, duration: 42.541s, episode steps: 1000, steps per second:  24, episode reward: -65.636, mean reward: -0.066 [-0.100,  6.773], mean action: 2.188 [0.000, 4.000],  loss: 0.194640, mae: 15.859864, mean_q: 20.000437
Track generation: 1064..1338 -> 274-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1142..1431 -> 289-tiles track
  40829/500000: episode: 41, duration: 41.175s, episode steps: 1000, steps per second:  24, episode reward: -6.250, mean reward: -0.006 [-0.100,  6.844], mean action: 1.934 [0.000, 4.000],  loss: 0.207303, mae: 15.671965, mean_q: 19.749729
Track generation: 1068..1344 -> 276-tiles track
  41829/500000: episode: 42, duration: 41.450s, episode steps: 1000, steps per second:  24, episode reward: -27.273, mean reward: -0.027 [-0.100,  7.173], mean action: 2.090 [0.000, 4.000],  loss: 0.193195, mae: 15.749320, mean_q: 19.860451
Track generation: 1184..1483 -> 299-tiles track
  42829/500000: episode: 43, duration: 39.929s, episode steps: 1000, steps per second:  25, episode reward: -73.154, mean reward: -0.073 [-0.100,  6.611], mean action: 2.119 [0.000, 4.000],  loss: 0.192561, mae: 15.729209, mean_q: 19.820156
Track generation: 1139..1428 -> 289-tiles track
  43829/500000: episode: 44, duration: 40.496s, episode steps: 1000, steps per second:  25, episode reward: -16.667, mean reward: -0.017 [-0.100,  6.844], mean action: 2.220 [0.000, 4.000],  loss: 0.167419, mae: 15.777150, mean_q: 19.891437
Track generation: 1156..1449 -> 293-tiles track
  44829/500000: episode: 45, duration: 40.957s, episode steps: 1000, steps per second:  24, episode reward: -69.178, mean reward: -0.069 [-0.100,  6.749], mean action: 1.858 [0.000, 4.000],  loss: 0.170034, mae: 15.823800, mean_q: 19.938735
Track generation: 1041..1314 -> 273-tiles track
  45829/500000: episode: 46, duration: 40.794s, episode steps: 1000, steps per second:  25, episode reward: -37.500, mean reward: -0.038 [-0.100,  7.253], mean action: 2.166 [0.000, 4.000],  loss: 0.152951, mae: 15.761355, mean_q: 19.853901
Track generation: 1031..1294 -> 263-tiles track
  46829/500000: episode: 47, duration: 41.359s, episode steps: 1000, steps per second:  24, episode reward: -23.664, mean reward: -0.024 [-0.100,  7.534], mean action: 2.512 [0.000, 4.000],  loss: 0.201365, mae: 15.800312, mean_q: 19.917231
Track generation: 1017..1275 -> 258-tiles track
  47829/500000: episode: 48, duration: 40.773s, episode steps: 1000, steps per second:  25, episode reward: -22.179, mean reward: -0.022 [-0.100,  7.682], mean action: 1.912 [0.000, 4.000],  loss: 0.152627, mae: 15.793716, mean_q: 19.892184
Track generation: 1144..1434 -> 290-tiles track
  48466/500000: episode: 49, duration: 31.126s, episode steps: 637, steps per second:  20, episode reward: -115.157, mean reward: -0.181 [-100.000,  6.820], mean action: 2.264 [0.000, 4.000],  loss: 0.162442, mae: 15.785792, mean_q: 19.885714
Track generation: 1133..1424 -> 291-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1275..1597 -> 322-tiles track
  49466/500000: episode: 50, duration: 49.142s, episode steps: 1000, steps per second:  20, episode reward: -31.464, mean reward: -0.031 [-0.100,  6.131], mean action: 1.819 [0.000, 4.000],  loss: 0.162594, mae: 15.778544, mean_q: 19.858143
Track generation: 1299..1628 -> 329-tiles track
  50466/500000: episode: 51, duration: 51.260s, episode steps: 1000, steps per second:  20, episode reward: -14.634, mean reward: -0.015 [-0.100,  5.998], mean action: 1.639 [0.000, 4.000],  loss: 0.170741, mae: 15.795909, mean_q: 19.890684
Track generation: 1193..1495 -> 302-tiles track
  51466/500000: episode: 52, duration: 45.773s, episode steps: 1000, steps per second:  22, episode reward: 16.279, mean reward:  0.016 [-0.100,  6.545], mean action: 1.887 [0.000, 4.000],  loss: 0.205006, mae: 15.764800, mean_q: 19.836696
Track generation: 1144..1434 -> 290-tiles track
  52466/500000: episode: 53, duration: 54.167s, episode steps: 1000, steps per second:  18, episode reward:  3.806, mean reward:  0.004 [-0.100,  6.820], mean action: 1.973 [0.000, 4.000],  loss: 0.163557, mae: 15.819147, mean_q: 19.899529
Track generation: 1200..1513 -> 313-tiles track
  53466/500000: episode: 54, duration: 56.447s, episode steps: 1000, steps per second:  18, episode reward: -67.949, mean reward: -0.068 [-0.100,  6.310], mean action: 2.375 [0.000, 4.000],  loss: 0.156093, mae: 15.849332, mean_q: 19.957011
Track generation: 1124..1409 -> 285-tiles track
  54466/500000: episode: 55, duration: 48.606s, episode steps: 1000, steps per second:  21, episode reward: -68.310, mean reward: -0.068 [-0.100,  6.942], mean action: 2.372 [0.000, 4.000],  loss: 0.160686, mae: 15.826403, mean_q: 19.926783
Track generation: 1130..1417 -> 287-tiles track
  55466/500000: episode: 56, duration: 49.584s, episode steps: 1000, steps per second:  20, episode reward: -12.587, mean reward: -0.013 [-0.100,  6.893], mean action: 2.020 [0.000, 4.000],  loss: 0.165918, mae: 15.710350, mean_q: 19.773764
Track generation: 1120..1412 -> 292-tiles track
  56466/500000: episode: 57, duration: 55.734s, episode steps: 1000, steps per second:  18, episode reward: 47.766, mean reward:  0.048 [-0.100,  6.773], mean action: 1.479 [0.000, 4.000],  loss: 0.182482, mae: 15.791773, mean_q: 19.860218
Track generation: 1063..1336 -> 273-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1088..1364 -> 276-tiles track
  57466/500000: episode: 58, duration: 49.630s, episode steps: 1000, steps per second:  20, episode reward: -9.091, mean reward: -0.009 [-0.100,  7.173], mean action: 2.207 [0.000, 4.000],  loss: 0.164951, mae: 15.731874, mean_q: 19.794787
Track generation: 1067..1344 -> 277-tiles track
  58466/500000: episode: 59, duration: 45.052s, episode steps: 1000, steps per second:  22, episode reward: -9.420, mean reward: -0.009 [-0.100,  7.146], mean action: 2.245 [0.000, 4.000],  loss: 0.171073, mae: 15.770746, mean_q: 19.827800
Track generation: 1132..1419 -> 287-tiles track
  59466/500000: episode: 60, duration: 42.537s, episode steps: 1000, steps per second:  24, episode reward: -51.049, mean reward: -0.051 [-0.100,  6.893], mean action: 1.795 [0.000, 4.000],  loss: 0.152513, mae: 15.777703, mean_q: 19.844075
Track generation: 1247..1563 -> 316-tiles track
  60466/500000: episode: 61, duration: 44.386s, episode steps: 1000, steps per second:  23, episode reward: -74.603, mean reward: -0.075 [-0.100,  6.249], mean action: 2.308 [0.000, 4.000],  loss: 0.160600, mae: 15.807156, mean_q: 19.890692
Track generation: 1082..1359 -> 277-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1022..1290 -> 268-tiles track
  61466/500000: episode: 62, duration: 43.450s, episode steps: 1000, steps per second:  23, episode reward: 16.105, mean reward:  0.016 [-0.100,  7.391], mean action: 1.957 [0.000, 4.000],  loss: 0.174616, mae: 15.813663, mean_q: 19.892611
Track generation: 1074..1354 -> 280-tiles track
  62466/500000: episode: 63, duration: 42.871s, episode steps: 1000, steps per second:  23, episode reward: 43.369, mean reward:  0.043 [-0.100,  7.068], mean action: 1.891 [0.000, 4.000],  loss: 0.149775, mae: 15.779291, mean_q: 19.848334
Track generation: 1143..1433 -> 290-tiles track
  63466/500000: episode: 64, duration: 46.885s, episode steps: 1000, steps per second:  21, episode reward: -30.796, mean reward: -0.031 [-0.100,  6.820], mean action: 2.268 [0.000, 4.000],  loss: 0.171320, mae: 15.896406, mean_q: 19.982814
Track generation: 998..1257 -> 259-tiles track
  64466/500000: episode: 65, duration: 44.239s, episode steps: 1000, steps per second:  23, episode reward: -37.984, mean reward: -0.038 [-0.100,  7.652], mean action: 2.323 [0.000, 4.000],  loss: 0.182893, mae: 15.872382, mean_q: 19.952074
Track generation: 910..1147 -> 237-tiles track
  65466/500000: episode: 66, duration: 44.168s, episode steps: 1000, steps per second:  23, episode reward: -66.102, mean reward: -0.066 [-0.100,  8.375], mean action: 1.558 [0.000, 4.000],  loss: 0.146841, mae: 15.819711, mean_q: 19.883977
Track generation: 1151..1444 -> 293-tiles track
  66466/500000: episode: 67, duration: 41.873s, episode steps: 1000, steps per second:  24, episode reward: -48.630, mean reward: -0.049 [-0.100,  6.749], mean action: 1.796 [0.000, 4.000],  loss: 0.154174, mae: 15.935427, mean_q: 20.021287
Track generation: 1212..1519 -> 307-tiles track
  67466/500000: episode: 68, duration: 42.421s, episode steps: 1000, steps per second:  24, episode reward: -1.961, mean reward: -0.002 [-0.100,  6.436], mean action: 1.805 [0.000, 4.000],  loss: 0.154246, mae: 15.862563, mean_q: 19.946042
Track generation: 1152..1444 -> 292-tiles track
  68466/500000: episode: 69, duration: 43.904s, episode steps: 1000, steps per second:  23, episode reward: -0.344, mean reward: -0.000 [-0.100,  6.773], mean action: 2.232 [0.000, 4.000],  loss: 0.153356, mae: 15.889523, mean_q: 19.975022
Track generation: 1098..1382 -> 284-tiles track
  69291/500000: episode: 70, duration: 36.048s, episode steps: 825, steps per second:  23, episode reward: -48.124, mean reward: -0.058 [-100.000,  6.967], mean action: 1.932 [0.000, 4.000],  loss: 0.177777, mae: 15.941267, mean_q: 20.033861
Track generation: 1167..1463 -> 296-tiles track
  70291/500000: episode: 71, duration: 43.170s, episode steps: 1000, steps per second:  23, episode reward: -28.814, mean reward: -0.029 [-0.100,  6.680], mean action: 2.396 [0.000, 4.000],  loss: 0.164972, mae: 15.882745, mean_q: 19.972384
Track generation: 1090..1367 -> 277-tiles track
  71291/500000: episode: 72, duration: 42.291s, episode steps: 1000, steps per second:  24, episode reward: -49.275, mean reward: -0.049 [-0.100,  7.146], mean action: 1.886 [0.000, 4.000],  loss: 0.181510, mae: 16.032179, mean_q: 20.166496
Track generation: 1201..1505 -> 304-tiles track
  72291/500000: episode: 73, duration: 43.668s, episode steps: 1000, steps per second:  23, episode reward: -43.894, mean reward: -0.044 [-0.100,  6.501], mean action: 1.593 [0.000, 4.000],  loss: 0.170901, mae: 16.040448, mean_q: 20.167288
Track generation: 1059..1336 -> 277-tiles track
  73291/500000: episode: 74, duration: 41.571s, episode steps: 1000, steps per second:  24, episode reward: -45.652, mean reward: -0.046 [-0.100,  7.146], mean action: 2.736 [0.000, 4.000],  loss: 0.189500, mae: 15.961083, mean_q: 20.072501
Track generation: 1253..1570 -> 317-tiles track
  74291/500000: episode: 75, duration: 42.769s, episode steps: 1000, steps per second:  23, episode reward: -58.861, mean reward: -0.059 [-0.100,  6.229], mean action: 1.868 [0.000, 4.000],  loss: 0.146947, mae: 16.026225, mean_q: 20.150440
Track generation: 1084..1359 -> 275-tiles track
  75291/500000: episode: 76, duration: 42.107s, episode steps: 1000, steps per second:  24, episode reward: -12.409, mean reward: -0.012 [-0.100,  7.199], mean action: 2.082 [0.000, 4.000],  loss: 0.164792, mae: 15.969120, mean_q: 20.072144
Track generation: 1006..1271 -> 265-tiles track
  76291/500000: episode: 77, duration: 44.345s, episode steps: 1000, steps per second:  23, episode reward: 17.424, mean reward:  0.017 [-0.100,  7.476], mean action: 1.799 [0.000, 4.000],  loss: 0.155925, mae: 15.977943, mean_q: 20.097560
Track generation: 972..1219 -> 247-tiles track
  77291/500000: episode: 78, duration: 42.186s, episode steps: 1000, steps per second:  24, episode reward: -2.439, mean reward: -0.002 [-0.100,  8.030], mean action: 1.950 [0.000, 4.000],  loss: 0.149066, mae: 16.022358, mean_q: 20.142828
Track generation: 1135..1423 -> 288-tiles track
  78291/500000: episode: 79, duration: 42.527s, episode steps: 1000, steps per second:  24, episode reward: -30.314, mean reward: -0.030 [-0.100,  6.869], mean action: 2.033 [0.000, 4.000],  loss: 0.151834, mae: 15.886879, mean_q: 19.975139
Track generation: 1127..1420 -> 293-tiles track
  79291/500000: episode: 80, duration: 43.714s, episode steps: 1000, steps per second:  23, episode reward: -14.384, mean reward: -0.014 [-0.100,  6.749], mean action: 2.226 [0.000, 4.000],  loss: 0.158729, mae: 15.915037, mean_q: 20.017937
Track generation: 956..1199 -> 243-tiles track
  80291/500000: episode: 81, duration: 41.295s, episode steps: 1000, steps per second:  24, episode reward: -4.959, mean reward: -0.005 [-0.100,  8.164], mean action: 2.049 [0.000, 4.000],  loss: 0.161267, mae: 15.921708, mean_q: 20.010277
Track generation: 1174..1475 -> 301-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1272..1594 -> 322-tiles track
  81291/500000: episode: 82, duration: 43.383s, episode steps: 1000, steps per second:  23, episode reward: -31.464, mean reward: -0.031 [-0.100,  6.131], mean action: 2.096 [0.000, 4.000],  loss: 0.167623, mae: 15.965037, mean_q: 20.079258
Track generation: 1171..1468 -> 297-tiles track
  82291/500000: episode: 83, duration: 43.525s, episode steps: 1000, steps per second:  23, episode reward: 21.622, mean reward:  0.022 [-0.100,  6.657], mean action: 2.121 [0.000, 4.000],  loss: 0.180175, mae: 15.889002, mean_q: 19.975045
Track generation: 1071..1344 -> 273-tiles track
  83291/500000: episode: 84, duration: 42.461s, episode steps: 1000, steps per second:  24, episode reward: 13.971, mean reward:  0.014 [-0.100,  7.253], mean action: 2.208 [0.000, 4.000],  loss: 0.171990, mae: 15.858755, mean_q: 19.933647
Track generation: 1183..1483 -> 300-tiles track
  84291/500000: episode: 85, duration: 43.470s, episode steps: 1000, steps per second:  23, episode reward: -29.766, mean reward: -0.030 [-0.100,  6.589], mean action: 2.266 [0.000, 4.000],  loss: 0.170840, mae: 15.867501, mean_q: 19.938327
Track generation: 1013..1278 -> 265-tiles track
  85291/500000: episode: 86, duration: 42.929s, episode steps: 1000, steps per second:  23, episode reward: -16.667, mean reward: -0.017 [-0.100,  7.476], mean action: 2.279 [0.000, 4.000],  loss: 0.146459, mae: 15.866238, mean_q: 19.941743
Track generation: 1069..1345 -> 276-tiles track
  86291/500000: episode: 87, duration: 41.934s, episode steps: 1000, steps per second:  24, episode reward: -45.455, mean reward: -0.045 [-0.100,  7.173], mean action: 1.788 [0.000, 4.000],  loss: 0.165300, mae: 15.872735, mean_q: 19.947347
Track generation: 1064..1334 -> 270-tiles track
  87291/500000: episode: 88, duration: 43.574s, episode steps: 1000, steps per second:  23, episode reward: -47.955, mean reward: -0.048 [-0.100,  7.335], mean action: 1.561 [0.000, 4.000],  loss: 0.147207, mae: 15.818792, mean_q: 19.886247
Track generation: 841..1060 -> 219-tiles track
  88291/500000: episode: 89, duration: 42.926s, episode steps: 1000, steps per second:  23, episode reward:  5.505, mean reward:  0.006 [-0.100,  9.074], mean action: 2.553 [0.000, 4.000],  loss: 0.195783, mae: 15.851934, mean_q: 19.913097
Track generation: 1259..1578 -> 319-tiles track
  89291/500000: episode: 90, duration: 47.756s, episode steps: 1000, steps per second:  21, episode reward: -43.396, mean reward: -0.043 [-0.100,  6.189], mean action: 2.123 [0.000, 4.000],  loss: 0.156381, mae: 15.819570, mean_q: 19.899113
Track generation: 1076..1348 -> 272-tiles track
  90291/500000: episode: 91, duration: 43.122s, episode steps: 1000, steps per second:  23, episode reward: -48.339, mean reward: -0.048 [-0.100,  7.280], mean action: 2.370 [0.000, 4.000],  loss: 0.157333, mae: 15.848838, mean_q: 19.915910
Track generation: 1263..1583 -> 320-tiles track
  91291/500000: episode: 92, duration: 44.094s, episode steps: 1000, steps per second:  23, episode reward: -34.169, mean reward: -0.034 [-0.100,  6.170], mean action: 1.991 [0.000, 4.000],  loss: 0.172577, mae: 15.907607, mean_q: 19.985864
Track generation: 1391..1743 -> 352-tiles track
  92291/500000: episode: 93, duration: 45.619s, episode steps: 1000, steps per second:  22, episode reward: -23.077, mean reward: -0.023 [-0.100,  5.598], mean action: 2.438 [0.000, 4.000],  loss: 0.149839, mae: 15.864539, mean_q: 19.945524
Track generation: 1043..1308 -> 265-tiles track
  93291/500000: episode: 94, duration: 43.294s, episode steps: 1000, steps per second:  23, episode reward: -58.333, mean reward: -0.058 [-0.100,  7.476], mean action: 2.324 [0.000, 4.000],  loss: 0.176541, mae: 15.882984, mean_q: 19.954016
Track generation: 1072..1344 -> 272-tiles track
  94291/500000: episode: 95, duration: 42.660s, episode steps: 1000, steps per second:  23, episode reward: -11.439, mean reward: -0.011 [-0.100,  7.280], mean action: 2.110 [0.000, 4.000],  loss: 0.151308, mae: 15.883933, mean_q: 19.967466
Track generation: 1280..1604 -> 324-tiles track
  95291/500000: episode: 96, duration: 44.136s, episode steps: 1000, steps per second:  23, episode reward: -50.464, mean reward: -0.050 [-0.100,  6.092], mean action: 2.326 [0.000, 4.000],  loss: 0.150892, mae: 15.953711, mean_q: 20.048641
Track generation: 1083..1359 -> 276-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1111..1398 -> 287-tiles track
  96291/500000: episode: 97, duration: 43.861s, episode steps: 1000, steps per second:  23, episode reward:  8.392, mean reward:  0.008 [-0.100,  6.893], mean action: 2.526 [0.000, 4.000],  loss: 0.152731, mae: 15.926912, mean_q: 20.019750
Track generation: 1125..1410 -> 285-tiles track
  97291/500000: episode: 98, duration: 44.058s, episode steps: 1000, steps per second:  23, episode reward: -19.014, mean reward: -0.019 [-0.100,  6.942], mean action: 2.194 [0.000, 4.000],  loss: 0.142893, mae: 15.931097, mean_q: 20.024647
Track generation: 1117..1408 -> 291-tiles track
  98291/500000: episode: 99, duration: 43.291s, episode steps: 1000, steps per second:  23, episode reward: 58.621, mean reward:  0.059 [-0.100,  6.797], mean action: 1.857 [0.000, 4.000],  loss: 0.167166, mae: 15.996090, mean_q: 20.107954
Track generation: 1252..1569 -> 317-tiles track
  99291/500000: episode: 100, duration: 44.409s, episode steps: 1000, steps per second:  23, episode reward: -33.544, mean reward: -0.034 [-0.100,  6.229], mean action: 3.288 [0.000, 4.000],  loss: 0.148086, mae: 15.969269, mean_q: 20.064468
Track generation: 1038..1302 -> 264-tiles track
 100291/500000: episode: 101, duration: 43.511s, episode steps: 1000, steps per second:  23, episode reward: -23.954, mean reward: -0.024 [-0.100,  7.505], mean action: 2.187 [0.000, 4.000],  loss: 0.167627, mae: 15.949769, mean_q: 20.024688
Track generation: 1051..1320 -> 269-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1103..1383 -> 280-tiles track
 101291/500000: episode: 102, duration: 44.500s, episode steps: 1000, steps per second:  22, episode reward: -71.326, mean reward: -0.071 [-0.100,  7.068], mean action: 2.243 [0.000, 4.000],  loss: 0.168423, mae: 15.957820, mean_q: 20.037981
Track generation: 1127..1413 -> 286-tiles track
 102291/500000: episode: 103, duration: 44.197s, episode steps: 1000, steps per second:  23, episode reward: 12.281, mean reward:  0.012 [-0.100,  6.918], mean action: 1.790 [0.000, 4.000],  loss: 0.178384, mae: 15.980516, mean_q: 20.072249
Track generation: 1211..1518 -> 307-tiles track
 103291/500000: episode: 104, duration: 44.334s, episode steps: 1000, steps per second:  23, episode reward: -44.444, mean reward: -0.044 [-0.100,  6.436], mean action: 2.167 [0.000, 4.000],  loss: 0.163189, mae: 15.963865, mean_q: 20.042646
Track generation: 1273..1596 -> 323-tiles track
 104291/500000: episode: 105, duration: 45.099s, episode steps: 1000, steps per second:  22, episode reward: -47.205, mean reward: -0.047 [-0.100,  6.111], mean action: 2.312 [0.000, 4.000],  loss: 0.155047, mae: 15.973275, mean_q: 20.064551
Track generation: 1145..1443 -> 298-tiles track
 105291/500000: episode: 106, duration: 43.879s, episode steps: 1000, steps per second:  23, episode reward: 51.515, mean reward:  0.052 [-0.100,  6.634], mean action: 2.971 [0.000, 4.000],  loss: 0.156154, mae: 15.987548, mean_q: 20.081537
Track generation: 1181..1487 -> 306-tiles track
 105964/500000: episode: 107, duration: 30.364s, episode steps: 673, steps per second:  22, episode reward: -29.495, mean reward: -0.044 [-100.000,  6.457], mean action: 1.814 [0.000, 4.000],  loss: 0.170357, mae: 15.935493, mean_q: 20.008199
Track generation: 1098..1379 -> 281-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1067..1337 -> 270-tiles track
 106964/500000: episode: 108, duration: 43.936s, episode steps: 1000, steps per second:  23, episode reward:  4.089, mean reward:  0.004 [-0.100,  7.335], mean action: 2.155 [0.000, 4.000],  loss: 0.192818, mae: 16.000033, mean_q: 20.094427
Track generation: 1176..1474 -> 298-tiles track
 107964/500000: episode: 109, duration: 44.071s, episode steps: 1000, steps per second:  23, episode reward: -32.660, mean reward: -0.033 [-0.100,  6.634], mean action: 2.108 [0.000, 4.000],  loss: 0.166530, mae: 15.984088, mean_q: 20.074378
Track generation: 1039..1303 -> 264-tiles track
 108964/500000: episode: 110, duration: 43.362s, episode steps: 1000, steps per second:  23, episode reward: -23.954, mean reward: -0.024 [-0.100,  7.505], mean action: 2.071 [0.000, 4.000],  loss: 0.156448, mae: 16.008400, mean_q: 20.110327
Track generation: 1120..1404 -> 284-tiles track
 109964/500000: episode: 111, duration: 44.866s, episode steps: 1000, steps per second:  22, episode reward: -25.795, mean reward: -0.026 [-0.100,  6.967], mean action: 2.225 [0.000, 4.000],  loss: 0.161879, mae: 16.008070, mean_q: 20.114911
Track generation: 1219..1529 -> 310-tiles track
 110964/500000: episode: 112, duration: 44.392s, episode steps: 1000, steps per second:  23, episode reward: 123.301, mean reward:  0.123 [-0.100,  6.372], mean action: 1.523 [0.000, 4.000],  loss: 0.190155, mae: 15.946181, mean_q: 20.040908
Track generation: 1078..1351 -> 273-tiles track
 111964/500000: episode: 113, duration: 43.524s, episode steps: 1000, steps per second:  23, episode reward: -4.412, mean reward: -0.004 [-0.100,  7.253], mean action: 1.913 [0.000, 4.000],  loss: 0.194047, mae: 15.886444, mean_q: 19.954097
Track generation: 1235..1548 -> 313-tiles track
 112964/500000: episode: 114, duration: 46.026s, episode steps: 1000, steps per second:  22, episode reward:  8.974, mean reward:  0.009 [-0.100,  6.310], mean action: 2.053 [0.000, 4.000],  loss: 0.171847, mae: 15.974697, mean_q: 20.060733
Track generation: 1215..1523 -> 308-tiles track
 113964/500000: episode: 115, duration: 46.138s, episode steps: 1000, steps per second:  22, episode reward: -25.081, mean reward: -0.025 [-0.100,  6.415], mean action: 1.859 [0.000, 4.000],  loss: 0.171247, mae: 15.983844, mean_q: 20.078579
Track generation: 982..1235 -> 253-tiles track
 114964/500000: episode: 116, duration: 44.446s, episode steps: 1000, steps per second:  22, episode reward: 30.952, mean reward:  0.031 [-0.100,  7.837], mean action: 1.877 [0.000, 4.000],  loss: 0.190374, mae: 15.947948, mean_q: 20.028060
Track generation: 1104..1384 -> 280-tiles track
 115964/500000: episode: 117, duration: 46.998s, episode steps: 1000, steps per second:  21, episode reward: -28.315, mean reward: -0.028 [-0.100,  7.068], mean action: 3.311 [0.000, 4.000],  loss: 0.170458, mae: 16.015043, mean_q: 20.124538
Track generation: 1424..1778 -> 354-tiles track
 116964/500000: episode: 118, duration: 50.266s, episode steps: 1000, steps per second:  20, episode reward: -34.844, mean reward: -0.035 [-0.100,  5.566], mean action: 2.444 [0.000, 4.000],  loss: 0.152673, mae: 15.892039, mean_q: 19.964116
Track generation: 1092..1370 -> 278-tiles track
 117964/500000: episode: 119, duration: 46.637s, episode steps: 1000, steps per second:  21, episode reward: -63.899, mean reward: -0.064 [-0.100,  7.120], mean action: 1.545 [0.000, 4.000],  loss: 0.164162, mae: 15.939387, mean_q: 20.023769
Track generation: 1102..1391 -> 289-tiles track
 118804/500000: episode: 120, duration: 39.643s, episode steps: 840, steps per second:  21, episode reward: -6.817, mean reward: -0.008 [-100.000,  6.844], mean action: 1.727 [0.000, 4.000],  loss: 0.168856, mae: 16.001179, mean_q: 20.102533
Track generation: 993..1254 -> 261-tiles track
 119804/500000: episode: 121, duration: 46.199s, episode steps: 1000, steps per second:  22, episode reward:  7.692, mean reward:  0.008 [-0.100,  7.592], mean action: 2.299 [0.000, 4.000],  loss: 0.155712, mae: 15.922055, mean_q: 20.011869
Track generation: 1064..1341 -> 277-tiles track
 120804/500000: episode: 122, duration: 45.466s, episode steps: 1000, steps per second:  22, episode reward: 73.913, mean reward:  0.074 [-0.100,  7.146], mean action: 2.061 [0.000, 4.000],  loss: 0.184882, mae: 15.839033, mean_q: 19.890607
Track generation: 1104..1384 -> 280-tiles track
 121804/500000: episode: 123, duration: 46.153s, episode steps: 1000, steps per second:  22, episode reward: 43.369, mean reward:  0.043 [-0.100,  7.068], mean action: 1.452 [0.000, 4.000],  loss: 0.165223, mae: 15.773646, mean_q: 19.809353
Track generation: 1229..1546 -> 317-tiles track
 122804/500000: episode: 124, duration: 47.855s, episode steps: 1000, steps per second:  21, episode reward: -33.544, mean reward: -0.034 [-0.100,  6.229], mean action: 2.118 [0.000, 4.000],  loss: 0.207560, mae: 15.859454, mean_q: 19.924620
Track generation: 1198..1502 -> 304-tiles track
 123804/500000: episode: 125, duration: 46.945s, episode steps: 1000, steps per second:  21, episode reward: -4.290, mean reward: -0.004 [-0.100,  6.501], mean action: 1.883 [0.000, 4.000],  loss: 0.208985, mae: 15.825438, mean_q: 19.891669
Track generation: 1319..1653 -> 334-tiles track
 124804/500000: episode: 126, duration: 48.956s, episode steps: 1000, steps per second:  20, episode reward: 41.141, mean reward:  0.041 [-0.100,  5.906], mean action: 1.819 [0.000, 4.000],  loss: 0.174278, mae: 15.834651, mean_q: 19.887993
Track generation: 1109..1397 -> 288-tiles track
 125704/500000: episode: 127, duration: 42.122s, episode steps: 900, steps per second:  21, episode reward: -88.855, mean reward: -0.099 [-100.000,  6.869], mean action: 1.597 [0.000, 4.000],  loss: 0.198947, mae: 15.857178, mean_q: 19.917179
Track generation: 1058..1326 -> 268-tiles track
 126245/500000: episode: 128, duration: 24.180s, episode steps: 541, steps per second:  22, episode reward: -30.404, mean reward: -0.056 [-100.000,  7.391], mean action: 1.861 [0.000, 4.000],  loss: 0.171982, mae: 15.921535, mean_q: 20.007136
Track generation: 1207..1513 -> 306-tiles track
 127245/500000: episode: 129, duration: 47.327s, episode steps: 1000, steps per second:  21, episode reward: -47.541, mean reward: -0.048 [-0.100,  6.457], mean action: 2.415 [0.000, 4.000],  loss: 0.189725, mae: 15.869201, mean_q: 19.926271
Track generation: 1088..1364 -> 276-tiles track
 128245/500000: episode: 130, duration: 47.699s, episode steps: 1000, steps per second:  21, episode reward: 110.909, mean reward:  0.111 [-0.100,  7.173], mean action: 1.710 [0.000, 4.000],  loss: 0.207925, mae: 15.821262, mean_q: 19.869366
Track generation: 1160..1454 -> 294-tiles track
 129245/500000: episode: 131, duration: 50.499s, episode steps: 1000, steps per second:  20, episode reward: -21.502, mean reward: -0.022 [-0.100,  6.726], mean action: 2.093 [0.000, 4.000],  loss: 0.181830, mae: 15.775764, mean_q: 19.815646
Track generation: 1141..1430 -> 289-tiles track
 129670/500000: episode: 132, duration: 20.374s, episode steps: 425, steps per second:  21, episode reward: -72.956, mean reward: -0.172 [-100.000,  6.844], mean action: 1.565 [0.000, 4.000],  loss: 0.153153, mae: 15.819603, mean_q: 19.887766
Track generation: 1087..1364 -> 277-tiles track
 130670/500000: episode: 133, duration: 51.289s, episode steps: 1000, steps per second:  19, episode reward: -5.797, mean reward: -0.006 [-0.100,  7.146], mean action: 1.518 [0.000, 4.000],  loss: 0.202517, mae: 15.752901, mean_q: 19.772926
Track generation: 1073..1348 -> 275-tiles track
 131670/500000: episode: 134, duration: 50.777s, episode steps: 1000, steps per second:  20, episode reward: -19.708, mean reward: -0.020 [-0.100,  7.199], mean action: 2.546 [0.000, 4.000],  loss: 0.191790, mae: 15.682593, mean_q: 19.695520
Track generation: 1188..1489 -> 301-tiles track
 132670/500000: episode: 135, duration: 48.810s, episode steps: 1000, steps per second:  20, episode reward: -13.333, mean reward: -0.013 [-0.100,  6.567], mean action: 2.954 [0.000, 4.000],  loss: 0.185771, mae: 15.667819, mean_q: 19.681674
Track generation: 1272..1594 -> 322-tiles track
 133670/500000: episode: 136, duration: 49.486s, episode steps: 1000, steps per second:  20, episode reward: -31.464, mean reward: -0.031 [-0.100,  6.131], mean action: 1.544 [0.000, 4.000],  loss: 0.192394, mae: 15.659032, mean_q: 19.670633
Track generation: 1200..1504 -> 304-tiles track
 134670/500000: episode: 137, duration: 50.699s, episode steps: 1000, steps per second:  20, episode reward: 22.112, mean reward:  0.022 [-0.100,  6.501], mean action: 2.151 [0.000, 4.000],  loss: 0.205270, mae: 15.656153, mean_q: 19.671520
Track generation: 1008..1264 -> 256-tiles track
 135670/500000: episode: 138, duration: 49.910s, episode steps: 1000, steps per second:  20, episode reward: 150.980, mean reward:  0.151 [-0.100,  7.743], mean action: 1.754 [0.000, 4.000],  loss: 0.171439, mae: 15.697506, mean_q: 19.729619
Track generation: 1055..1323 -> 268-tiles track
 136670/500000: episode: 139, duration: 48.551s, episode steps: 1000, steps per second:  21, episode reward: -62.547, mean reward: -0.063 [-0.100,  7.391], mean action: 1.951 [0.000, 4.000],  loss: 0.187166, mae: 15.669190, mean_q: 19.688169
Track generation: 1176..1474 -> 298-tiles track
 137670/500000: episode: 140, duration: 48.305s, episode steps: 1000, steps per second:  21, episode reward: 14.478, mean reward:  0.014 [-0.100,  6.634], mean action: 1.989 [0.000, 4.000],  loss: 0.182570, mae: 15.681936, mean_q: 19.691913
Track generation: 1348..1689 -> 341-tiles track
 138670/500000: episode: 141, duration: 49.314s, episode steps: 1000, steps per second:  20, episode reward: -52.941, mean reward: -0.053 [-0.100,  5.782], mean action: 1.824 [0.000, 4.000],  loss: 0.176503, mae: 15.740107, mean_q: 19.778275
Track generation: 1078..1358 -> 280-tiles track
 139670/500000: episode: 142, duration: 47.176s, episode steps: 1000, steps per second:  21, episode reward: -49.821, mean reward: -0.050 [-0.100,  7.068], mean action: 2.269 [0.000, 4.000],  loss: 0.174476, mae: 15.681392, mean_q: 19.707608
Track generation: 1136..1424 -> 288-tiles track
 140670/500000: episode: 143, duration: 46.459s, episode steps: 1000, steps per second:  22, episode reward: 11.498, mean reward:  0.011 [-0.100,  6.869], mean action: 1.887 [0.000, 4.000],  loss: 0.175702, mae: 15.718083, mean_q: 19.750291
Track generation: 1183..1483 -> 300-tiles track
 141107/500000: episode: 144, duration: 20.655s, episode steps: 437, steps per second:  21, episode reward: -76.710, mean reward: -0.176 [-100.000,  6.589], mean action: 2.073 [0.000, 4.000],  loss: 0.194671, mae: 15.630614, mean_q: 19.619765
Track generation: 1139..1428 -> 289-tiles track
 142107/500000: episode: 145, duration: 49.022s, episode steps: 1000, steps per second:  20, episode reward: 122.222, mean reward:  0.122 [-0.100,  6.844], mean action: 2.260 [0.000, 4.000],  loss: 0.188924, mae: 15.720549, mean_q: 19.738166
Track generation: 1155..1448 -> 293-tiles track
 143107/500000: episode: 146, duration: 47.723s, episode steps: 1000, steps per second:  21, episode reward:  2.740, mean reward:  0.003 [-0.100,  6.749], mean action: 2.417 [0.000, 4.000],  loss: 0.211887, mae: 15.763004, mean_q: 19.777789
Track generation: 1099..1378 -> 279-tiles track
 144107/500000: episode: 147, duration: 48.149s, episode steps: 1000, steps per second:  21, episode reward: -24.460, mean reward: -0.024 [-0.100,  7.094], mean action: 2.274 [0.000, 4.000],  loss: 0.189497, mae: 15.666624, mean_q: 19.683884
Track generation: 1030..1299 -> 269-tiles track
 145107/500000: episode: 148, duration: 47.900s, episode steps: 1000, steps per second:  21, episode reward: 127.612, mean reward:  0.128 [-0.100,  7.363], mean action: 1.506 [0.000, 4.000],  loss: 0.152022, mae: 15.754896, mean_q: 19.783449
Track generation: 1054..1329 -> 275-tiles track
 146107/500000: episode: 149, duration: 47.837s, episode steps: 1000, steps per second:  21, episode reward: -37.956, mean reward: -0.038 [-0.100,  7.199], mean action: 1.666 [0.000, 4.000],  loss: 0.222736, mae: 15.765808, mean_q: 19.788927
Track generation: 1003..1258 -> 255-tiles track
 147107/500000: episode: 150, duration: 48.380s, episode steps: 1000, steps per second:  21, episode reward: 14.173, mean reward:  0.014 [-0.100,  7.774], mean action: 2.137 [0.000, 4.000],  loss: 0.170298, mae: 15.791367, mean_q: 19.832263
Track generation: 1147..1438 -> 291-tiles track
 148107/500000: episode: 151, duration: 50.924s, episode steps: 1000, steps per second:  20, episode reward: -55.172, mean reward: -0.055 [-0.100,  6.797], mean action: 2.211 [0.000, 4.000],  loss: 0.174967, mae: 15.802098, mean_q: 19.845973
Track generation: 1088..1371 -> 283-tiles track
 149107/500000: episode: 152, duration: 51.588s, episode steps: 1000, steps per second:  19, episode reward: 31.206, mean reward:  0.031 [-0.100,  6.992], mean action: 2.366 [0.000, 4.000],  loss: 0.158637, mae: 15.733295, mean_q: 19.749115
Track generation: 1187..1488 -> 301-tiles track
 150107/500000: episode: 153, duration: 49.803s, episode steps: 1000, steps per second:  20, episode reward: 270.000, mean reward:  0.270 [-0.100,  6.567], mean action: 1.520 [0.000, 4.000],  loss: 0.190720, mae: 15.773961, mean_q: 19.810629
Track generation: 1048..1317 -> 269-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1216..1524 -> 308-tiles track
 150533/500000: episode: 154, duration: 22.072s, episode steps: 426, steps per second:  19, episode reward: -83.868, mean reward: -0.197 [-100.000,  6.415], mean action: 2.110 [0.000, 4.000],  loss: 0.176530, mae: 15.645776, mean_q: 19.671449
Track generation: 1044..1317 -> 273-tiles track
 151533/500000: episode: 155, duration: 49.509s, episode steps: 1000, steps per second:  20, episode reward: 69.118, mean reward:  0.069 [-0.100,  7.253], mean action: 2.018 [0.000, 4.000],  loss: 0.174543, mae: 15.662198, mean_q: 19.683226
Track generation: 1103..1383 -> 280-tiles track
 152533/500000: episode: 156, duration: 50.539s, episode steps: 1000, steps per second:  20, episode reward: 21.864, mean reward:  0.022 [-0.100,  7.068], mean action: 1.796 [0.000, 4.000],  loss: 0.178431, mae: 15.676896, mean_q: 19.688422
Track generation: 1107..1388 -> 281-tiles track
 153533/500000: episode: 157, duration: 51.078s, episode steps: 1000, steps per second:  20, episode reward: -25.000, mean reward: -0.025 [-0.100,  7.043], mean action: 2.014 [0.000, 4.000],  loss: 0.175133, mae: 15.700355, mean_q: 19.710665
Track generation: 1191..1493 -> 302-tiles track
 154533/500000: episode: 158, duration: 50.817s, episode steps: 1000, steps per second:  20, episode reward: -16.944, mean reward: -0.017 [-0.100,  6.545], mean action: 2.177 [0.000, 4.000],  loss: 0.204619, mae: 15.672985, mean_q: 19.679101
Track generation: 1164..1467 -> 303-tiles track
 155533/500000: episode: 159, duration: 51.100s, episode steps: 1000, steps per second:  20, episode reward: 164.901, mean reward:  0.165 [-0.100,  6.523], mean action: 1.877 [0.000, 4.000],  loss: 0.179701, mae: 15.616780, mean_q: 19.605614
Track generation: 1224..1534 -> 310-tiles track
 156533/500000: episode: 160, duration: 53.832s, episode steps: 1000, steps per second:  19, episode reward: -48.220, mean reward: -0.048 [-0.100,  6.372], mean action: 2.216 [0.000, 4.000],  loss: 0.190227, mae: 15.639531, mean_q: 19.629711
Track generation: 1266..1587 -> 321-tiles track
 157533/500000: episode: 161, duration: 53.528s, episode steps: 1000, steps per second:  19, episode reward: -34.375, mean reward: -0.034 [-0.100,  6.150], mean action: 1.702 [0.000, 4.000],  loss: 0.195766, mae: 15.618397, mean_q: 19.605026
Track generation: 1232..1549 -> 317-tiles track
 158533/500000: episode: 162, duration: 54.346s, episode steps: 1000, steps per second:  18, episode reward: 55.063, mean reward:  0.055 [-0.100,  6.229], mean action: 2.106 [0.000, 4.000],  loss: 0.169995, mae: 15.644866, mean_q: 19.654998
Track generation: 1064..1334 -> 270-tiles track
 159533/500000: episode: 163, duration: 53.177s, episode steps: 1000, steps per second:  19, episode reward: 11.524, mean reward:  0.012 [-0.100,  7.335], mean action: 1.498 [0.000, 4.000],  loss: 0.181978, mae: 15.712345, mean_q: 19.734092
Track generation: 1041..1310 -> 269-tiles track
 160533/500000: episode: 164, duration: 50.531s, episode steps: 1000, steps per second:  20, episode reward: 23.134, mean reward:  0.023 [-0.100,  7.363], mean action: 1.779 [0.000, 4.000],  loss: 0.191588, mae: 15.592829, mean_q: 19.583976
Track generation: 1244..1559 -> 315-tiles track
 161533/500000: episode: 165, duration: 51.842s, episode steps: 1000, steps per second:  19, episode reward: -77.707, mean reward: -0.078 [-0.100,  6.269], mean action: 1.887 [0.000, 4.000],  loss: 0.177245, mae: 15.556280, mean_q: 19.534162
Track generation: 1376..1724 -> 348-tiles track
 162533/500000: episode: 166, duration: 54.602s, episode steps: 1000, steps per second:  18, episode reward: -39.481, mean reward: -0.039 [-0.100,  5.664], mean action: 1.624 [0.000, 4.000],  loss: 0.163950, mae: 15.531623, mean_q: 19.498617
Track generation: 1091..1368 -> 277-tiles track
 163533/500000: episode: 167, duration: 52.702s, episode steps: 1000, steps per second:  19, episode reward: 121.014, mean reward:  0.121 [-0.100,  7.146], mean action: 2.004 [0.000, 4.000],  loss: 0.170833, mae: 15.570003, mean_q: 19.554878
Track generation: 1443..1808 -> 365-tiles track
 163795/500000: episode: 168, duration: 14.660s, episode steps: 262, steps per second:  18, episode reward: -68.408, mean reward: -0.261 [-100.000,  5.395], mean action: 1.966 [0.000, 4.000],  loss: 0.165806, mae: 15.576149, mean_q: 19.553769
Track generation: 1144..1434 -> 290-tiles track
 164795/500000: episode: 169, duration: 53.604s, episode steps: 1000, steps per second:  19, episode reward: 59.170, mean reward:  0.059 [-0.100,  6.820], mean action: 1.627 [0.000, 4.000],  loss: 0.204386, mae: 15.598935, mean_q: 19.591742
Track generation: 1299..1628 -> 329-tiles track
 165795/500000: episode: 170, duration: 54.404s, episode steps: 1000, steps per second:  18, episode reward:  0.610, mean reward:  0.001 [-0.100,  5.998], mean action: 2.172 [0.000, 4.000],  loss: 0.176158, mae: 15.594789, mean_q: 19.579445
Track generation: 1355..1708 -> 353-tiles track
 166795/500000: episode: 171, duration: 54.398s, episode steps: 1000, steps per second:  18, episode reward: 47.727, mean reward:  0.048 [-0.100,  5.582], mean action: 1.980 [0.000, 4.000],  loss: 0.166535, mae: 15.672625, mean_q: 19.684946
Track generation: 1016..1274 -> 258-tiles track
 167795/500000: episode: 172, duration: 51.709s, episode steps: 1000, steps per second:  19, episode reward: 59.533, mean reward:  0.060 [-0.100,  7.682], mean action: 1.875 [0.000, 4.000],  loss: 0.163066, mae: 15.610364, mean_q: 19.592105
Track generation: 1255..1573 -> 318-tiles track
 168795/500000: episode: 173, duration: 55.110s, episode steps: 1000, steps per second:  18, episode reward: -8.517, mean reward: -0.009 [-0.100,  6.209], mean action: 1.225 [0.000, 4.000],  loss: 0.176253, mae: 15.619811, mean_q: 19.609939
Track generation: 1188..1490 -> 302-tiles track
 169795/500000: episode: 174, duration: 52.904s, episode steps: 1000, steps per second:  19, episode reward: -40.199, mean reward: -0.040 [-0.100,  6.545], mean action: 2.867 [0.000, 4.000],  loss: 0.182163, mae: 15.555378, mean_q: 19.536587
Track generation: 1047..1313 -> 266-tiles track
 170795/500000: episode: 175, duration: 53.160s, episode steps: 1000, steps per second:  19, episode reward: -20.755, mean reward: -0.021 [-0.100,  7.447], mean action: 1.815 [0.000, 4.000],  loss: 0.180240, mae: 15.522259, mean_q: 19.491549
Track generation: 1225..1535 -> 310-tiles track
 171270/500000: episode: 176, duration: 25.701s, episode steps: 475, steps per second:  18, episode reward: -85.911, mean reward: -0.181 [-100.000,  6.372], mean action: 1.731 [0.000, 4.000],  loss: 0.183910, mae: 15.529748, mean_q: 19.507781
Track generation: 1167..1463 -> 296-tiles track
 171887/500000: episode: 177, duration: 32.328s, episode steps: 617, steps per second:  19, episode reward: -134.481, mean reward: -0.218 [-100.000,  6.680], mean action: 1.810 [0.000, 4.000],  loss: 0.166634, mae: 15.488850, mean_q: 19.449264
Track generation: 1097..1375 -> 278-tiles track
 172887/500000: episode: 178, duration: 55.071s, episode steps: 1000, steps per second:  18, episode reward: 37.184, mean reward:  0.037 [-0.100,  7.120], mean action: 1.951 [0.000, 4.000],  loss: 0.211747, mae: 15.459575, mean_q: 19.419276
Track generation: 1175..1473 -> 298-tiles track
 173887/500000: episode: 179, duration: 53.919s, episode steps: 1000, steps per second:  19, episode reward: -42.761, mean reward: -0.043 [-0.100,  6.634], mean action: 1.638 [0.000, 4.000],  loss: 0.182300, mae: 15.442700, mean_q: 19.386631
Track generation: 1013..1270 -> 257-tiles track
 174887/500000: episode: 180, duration: 54.373s, episode steps: 1000, steps per second:  18, episode reward:  1.562, mean reward:  0.002 [-0.100,  7.713], mean action: 2.209 [0.000, 4.000],  loss: 0.184605, mae: 15.486646, mean_q: 19.450636
Track generation: 1084..1359 -> 275-tiles track
 175887/500000: episode: 181, duration: 54.954s, episode steps: 1000, steps per second:  18, episode reward:  2.190, mean reward:  0.002 [-0.100,  7.199], mean action: 1.886 [0.000, 4.000],  loss: 0.209004, mae: 15.430763, mean_q: 19.363798
Track generation: 1195..1498 -> 303-tiles track
 176498/500000: episode: 182, duration: 33.842s, episode steps: 611, steps per second:  18, episode reward: -91.464, mean reward: -0.150 [-100.000,  6.523], mean action: 1.727 [0.000, 4.000],  loss: 0.155278, mae: 15.453577, mean_q: 19.404180
Track generation: 1199..1503 -> 304-tiles track
 177475/500000: episode: 183, duration: 53.937s, episode steps: 977, steps per second:  18, episode reward: -131.593, mean reward: -0.135 [-100.000,  6.501], mean action: 2.021 [0.000, 4.000],  loss: 0.185504, mae: 15.479468, mean_q: 19.437840
Track generation: 1040..1304 -> 264-tiles track
 177953/500000: episode: 184, duration: 26.213s, episode steps: 478, steps per second:  18, episode reward: -67.852, mean reward: -0.142 [-100.000,  7.505], mean action: 1.487 [0.000, 4.000],  loss: 0.177642, mae: 15.498693, mean_q: 19.462294
Track generation: 1275..1598 -> 323-tiles track
 178953/500000: episode: 185, duration: 55.037s, episode steps: 1000, steps per second:  18, episode reward: -16.149, mean reward: -0.016 [-0.100,  6.111], mean action: 2.008 [0.000, 4.000],  loss: 0.172658, mae: 15.435027, mean_q: 19.396296
Track generation: 1309..1641 -> 332-tiles track
 179953/500000: episode: 186, duration: 56.240s, episode steps: 1000, steps per second:  18, episode reward: 17.825, mean reward:  0.018 [-0.100,  5.942], mean action: 1.892 [0.000, 4.000],  loss: 0.175431, mae: 15.523253, mean_q: 19.505471
Track generation: 1238..1551 -> 313-tiles track
 180953/500000: episode: 187, duration: 54.722s, episode steps: 1000, steps per second:  18, episode reward: -71.154, mean reward: -0.071 [-0.100,  6.310], mean action: 2.208 [0.000, 4.000],  loss: 0.173958, mae: 15.377918, mean_q: 19.313697
Track generation: 1235..1555 -> 320-tiles track
 181953/500000: episode: 188, duration: 55.371s, episode steps: 1000, steps per second:  18, episode reward: 72.414, mean reward:  0.072 [-0.100,  6.170], mean action: 1.707 [0.000, 4.000],  loss: 0.178761, mae: 15.422871, mean_q: 19.367392
Track generation: 1269..1590 -> 321-tiles track
 182953/500000: episode: 189, duration: 55.585s, episode steps: 1000, steps per second:  18, episode reward: -9.375, mean reward: -0.009 [-0.100,  6.150], mean action: 1.657 [0.000, 4.000],  loss: 0.178663, mae: 15.334792, mean_q: 19.254352
Track generation: 1048..1319 -> 271-tiles track
 183953/500000: episode: 190, duration: 54.350s, episode steps: 1000, steps per second:  18, episode reward: -7.407, mean reward: -0.007 [-0.100,  7.307], mean action: 1.946 [0.000, 4.000],  loss: 0.187019, mae: 15.366001, mean_q: 19.291459
Track generation: 1238..1552 -> 314-tiles track
 184953/500000: episode: 191, duration: 56.958s, episode steps: 1000, steps per second:  18, episode reward: -32.907, mean reward: -0.033 [-0.100,  6.290], mean action: 1.658 [0.000, 4.000],  loss: 0.185318, mae: 15.318059, mean_q: 19.226323
Track generation: 1177..1475 -> 298-tiles track
 185953/500000: episode: 192, duration: 56.480s, episode steps: 1000, steps per second:  18, episode reward: -12.458, mean reward: -0.012 [-0.100,  6.634], mean action: 2.140 [0.000, 4.000],  loss: 0.205811, mae: 15.413209, mean_q: 19.359563
Track generation: 1185..1485 -> 300-tiles track
 186953/500000: episode: 193, duration: 56.664s, episode steps: 1000, steps per second:  18, episode reward: -46.488, mean reward: -0.046 [-0.100,  6.589], mean action: 2.010 [0.000, 4.000],  loss: 0.203420, mae: 15.331873, mean_q: 19.229434
Track generation: 1257..1584 -> 327-tiles track
 187953/500000: episode: 194, duration: 55.464s, episode steps: 1000, steps per second:  18, episode reward: -14.110, mean reward: -0.014 [-0.100,  6.035], mean action: 1.899 [0.000, 4.000],  loss: 0.179177, mae: 15.395846, mean_q: 19.326652
Track generation: 1112..1393 -> 281-tiles track
 188171/500000: episode: 195, duration: 12.106s, episode steps: 218, steps per second:  18, episode reward: -64.557, mean reward: -0.296 [-100.000,  7.043], mean action: 1.922 [0.000, 4.000],  loss: 0.193389, mae: 15.257023, mean_q: 19.152917
Track generation: 1088..1370 -> 282-tiles track
 188950/500000: episode: 196, duration: 43.226s, episode steps: 779, steps per second:  18, episode reward: 35.723, mean reward:  0.046 [-100.000,  7.017], mean action: 1.666 [0.000, 4.000],  loss: 0.189922, mae: 15.341470, mean_q: 19.258426
Track generation: 980..1232 -> 252-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1120..1404 -> 284-tiles track
 189212/500000: episode: 197, duration: 14.962s, episode steps: 262, steps per second:  18, episode reward: -58.962, mean reward: -0.225 [-100.000,  6.967], mean action: 1.863 [0.000, 4.000],  loss: 0.193544, mae: 15.332508, mean_q: 19.238524
Track generation: 1299..1628 -> 329-tiles track
 190212/500000: episode: 198, duration: 56.102s, episode steps: 1000, steps per second:  18, episode reward: -54.268, mean reward: -0.054 [-0.100,  5.998], mean action: 1.678 [0.000, 4.000],  loss: 0.182128, mae: 15.338736, mean_q: 19.248813
Track generation: 1092..1369 -> 277-tiles track
 191212/500000: episode: 199, duration: 55.867s, episode steps: 1000, steps per second:  18, episode reward:  1.449, mean reward:  0.001 [-0.100,  7.146], mean action: 1.578 [0.000, 4.000],  loss: 0.199637, mae: 15.197415, mean_q: 19.065709
Track generation: 1252..1572 -> 320-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1316..1649 -> 333-tiles track
 191548/500000: episode: 200, duration: 19.218s, episode steps: 336, steps per second:  17, episode reward: -106.392, mean reward: -0.317 [-100.000,  5.924], mean action: 1.562 [0.000, 4.000],  loss: 0.211282, mae: 15.138654, mean_q: 18.989474
Track generation: 1206..1520 -> 314-tiles track
 192548/500000: episode: 201, duration: 55.788s, episode steps: 1000, steps per second:  18, episode reward: -7.348, mean reward: -0.007 [-0.100,  6.290], mean action: 1.549 [0.000, 4.000],  loss: 0.166333, mae: 15.163256, mean_q: 19.044587
Track generation: 1291..1622 -> 331-tiles track
 192949/500000: episode: 202, duration: 22.646s, episode steps: 401, steps per second:  18, episode reward: -76.364, mean reward: -0.190 [-100.000,  5.961], mean action: 1.117 [0.000, 4.000],  loss: 0.231652, mae: 15.216422, mean_q: 19.119531
Track generation: 1145..1445 -> 300-tiles track
 193949/500000: episode: 203, duration: 54.970s, episode steps: 1000, steps per second:  18, episode reward: 10.368, mean reward:  0.010 [-0.100,  6.589], mean action: 1.294 [0.000, 4.000],  loss: 0.191842, mae: 15.155087, mean_q: 19.015788
Track generation: 1183..1490 -> 307-tiles track
 194949/500000: episode: 204, duration: 55.889s, episode steps: 1000, steps per second:  18, episode reward: -47.712, mean reward: -0.048 [-0.100,  6.436], mean action: 2.037 [0.000, 4.000],  loss: 0.195935, mae: 15.204634, mean_q: 19.084579
Track generation: 1106..1387 -> 281-tiles track
 195949/500000: episode: 205, duration: 55.367s, episode steps: 1000, steps per second:  18, episode reward: 17.857, mean reward:  0.018 [-0.100,  7.043], mean action: 1.645 [0.000, 4.000],  loss: 0.171120, mae: 15.246596, mean_q: 19.146298
Track generation: 936..1174 -> 238-tiles track
 196949/500000: episode: 206, duration: 54.954s, episode steps: 1000, steps per second:  18, episode reward: 39.241, mean reward:  0.039 [-0.100,  8.339], mean action: 2.209 [0.000, 4.000],  loss: 0.174009, mae: 15.220579, mean_q: 19.106375
Track generation: 1308..1639 -> 331-tiles track
 197949/500000: episode: 207, duration: 57.998s, episode steps: 1000, steps per second:  17, episode reward: 42.424, mean reward:  0.042 [-0.100,  5.961], mean action: 1.970 [0.000, 4.000],  loss: 0.180262, mae: 15.204304, mean_q: 19.082049
Track generation: 1243..1558 -> 315-tiles track
 198949/500000: episode: 208, duration: 58.853s, episode steps: 1000, steps per second:  17, episode reward: 40.127, mean reward:  0.040 [-0.100,  6.269], mean action: 1.860 [0.000, 4.000],  loss: 0.179029, mae: 15.189963, mean_q: 19.076911
Track generation: 1258..1577 -> 319-tiles track
 199896/500000: episode: 209, duration: 54.889s, episode steps: 947, steps per second:  17, episode reward: -125.418, mean reward: -0.132 [-100.000,  6.189], mean action: 1.570 [0.000, 4.000],  loss: 0.200257, mae: 15.244120, mean_q: 19.128880
Track generation: 1173..1475 -> 302-tiles track
 200896/500000: episode: 210, duration: 58.454s, episode steps: 1000, steps per second:  17, episode reward: 112.625, mean reward:  0.113 [-0.100,  6.545], mean action: 1.905 [0.000, 4.000],  loss: 0.204547, mae: 15.227685, mean_q: 19.128880
Track generation: 1112..1394 -> 282-tiles track
 201896/500000: episode: 211, duration: 60.385s, episode steps: 1000, steps per second:  17, episode reward: -11.032, mean reward: -0.011 [-0.100,  7.017], mean action: 1.677 [0.000, 4.000],  loss: 0.191389, mae: 15.189789, mean_q: 19.075368
Track generation: 1319..1653 -> 334-tiles track
 202896/500000: episode: 212, duration: 60.129s, episode steps: 1000, steps per second:  17, episode reward: -42.943, mean reward: -0.043 [-0.100,  5.906], mean action: 2.081 [0.000, 4.000],  loss: 0.190417, mae: 15.224089, mean_q: 19.105091
Track generation: 1253..1571 -> 318-tiles track
 203896/500000: episode: 213, duration: 59.166s, episode steps: 1000, steps per second:  17, episode reward: -30.599, mean reward: -0.031 [-0.100,  6.209], mean action: 2.078 [0.000, 4.000],  loss: 0.198932, mae: 15.156612, mean_q: 19.041316
Track generation: 1091..1374 -> 283-tiles track
 204896/500000: episode: 214, duration: 57.929s, episode steps: 1000, steps per second:  17, episode reward: -29.078, mean reward: -0.029 [-0.100,  6.992], mean action: 1.454 [0.000, 4.000],  loss: 0.207173, mae: 15.254401, mean_q: 19.159966
Track generation: 1122..1413 -> 291-tiles track
 205896/500000: episode: 215, duration: 58.933s, episode steps: 1000, steps per second:  17, episode reward: 10.345, mean reward:  0.010 [-0.100,  6.797], mean action: 2.336 [0.000, 4.000],  loss: 0.193296, mae: 15.175279, mean_q: 19.056453
Track generation: 1072..1344 -> 272-tiles track
 206896/500000: episode: 216, duration: 58.083s, episode steps: 1000, steps per second:  17, episode reward: -40.959, mean reward: -0.041 [-0.100,  7.280], mean action: 2.255 [0.000, 4.000],  loss: 0.205560, mae: 15.174750, mean_q: 19.067297
Track generation: 1018..1285 -> 267-tiles track
 207896/500000: episode: 217, duration: 58.467s, episode steps: 1000, steps per second:  17, episode reward: 219.549, mean reward:  0.220 [-0.100,  7.419], mean action: 2.031 [0.000, 4.000],  loss: 0.225586, mae: 15.149969, mean_q: 19.015455
Track generation: 1160..1454 -> 294-tiles track
 208896/500000: episode: 218, duration: 58.571s, episode steps: 1000, steps per second:  17, episode reward: -1.024, mean reward: -0.001 [-0.100,  6.726], mean action: 1.944 [0.000, 4.000],  loss: 0.175403, mae: 15.225813, mean_q: 19.123726
Track generation: 1075..1352 -> 277-tiles track
 209896/500000: episode: 219, duration: 58.171s, episode steps: 1000, steps per second:  17, episode reward: 168.116, mean reward:  0.168 [-0.100,  7.146], mean action: 1.777 [0.000, 4.000],  loss: 0.212871, mae: 15.188628, mean_q: 19.077077
Track generation: 1187..1488 -> 301-tiles track
 210896/500000: episode: 220, duration: 59.160s, episode steps: 1000, steps per second:  17, episode reward: 10.000, mean reward:  0.010 [-0.100,  6.567], mean action: 1.713 [0.000, 4.000],  loss: 0.177656, mae: 15.138551, mean_q: 19.031920
Track generation: 984..1238 -> 254-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1121..1406 -> 285-tiles track
 211896/500000: episode: 221, duration: 59.983s, episode steps: 1000, steps per second:  17, episode reward: -19.014, mean reward: -0.019 [-0.100,  6.942], mean action: 1.690 [0.000, 4.000],  loss: 0.215962, mae: 15.197814, mean_q: 19.098313
Track generation: 1252..1569 -> 317-tiles track
 212896/500000: episode: 222, duration: 60.525s, episode steps: 1000, steps per second:  17, episode reward: -33.544, mean reward: -0.034 [-0.100,  6.229], mean action: 1.874 [0.000, 4.000],  loss: 0.195418, mae: 15.133795, mean_q: 19.018156
Track generation: 1155..1448 -> 293-tiles track
 213896/500000: episode: 223, duration: 58.550s, episode steps: 1000, steps per second:  17, episode reward: -4.110, mean reward: -0.004 [-0.100,  6.749], mean action: 2.363 [0.000, 4.000],  loss: 0.216871, mae: 15.129986, mean_q: 19.000556
Track generation: 951..1198 -> 247-tiles track
 214896/500000: episode: 224, duration: 58.144s, episode steps: 1000, steps per second:  17, episode reward: 58.537, mean reward:  0.059 [-0.100,  8.030], mean action: 1.915 [0.000, 4.000],  loss: 0.194628, mae: 15.138731, mean_q: 19.011959
Track generation: 1043..1308 -> 265-tiles track
 215896/500000: episode: 225, duration: 59.165s, episode steps: 1000, steps per second:  17, episode reward:  6.061, mean reward:  0.006 [-0.100,  7.476], mean action: 2.119 [0.000, 4.000],  loss: 0.189136, mae: 15.155022, mean_q: 19.031171
Track generation: 1194..1496 -> 302-tiles track
 216478/500000: episode: 226, duration: 34.522s, episode steps: 582, steps per second:  17, episode reward: -91.655, mean reward: -0.157 [-100.000,  6.545], mean action: 1.514 [0.000, 4.000],  loss: 0.204139, mae: 15.124900, mean_q: 19.009403
Track generation: 1069..1347 -> 278-tiles track
 217478/500000: episode: 227, duration: 58.841s, episode steps: 1000, steps per second:  17, episode reward: 109.386, mean reward:  0.109 [-0.100,  7.120], mean action: 1.664 [0.000, 4.000],  loss: 0.232577, mae: 15.213175, mean_q: 19.110723
Track generation: 1200..1504 -> 304-tiles track
 218478/500000: episode: 228, duration: 59.983s, episode steps: 1000, steps per second:  17, episode reward: 91.419, mean reward:  0.091 [-0.100,  6.501], mean action: 1.777 [0.000, 4.000],  loss: 0.219008, mae: 15.157350, mean_q: 19.039620
Track generation: 1020..1282 -> 262-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1385..1738 -> 353-tiles track
 219478/500000: episode: 229, duration: 59.914s, episode steps: 1000, steps per second:  17, episode reward: -20.455, mean reward: -0.020 [-0.100,  5.582], mean action: 1.471 [0.000, 4.000],  loss: 0.182517, mae: 15.198619, mean_q: 19.096398
Track generation: 982..1238 -> 256-tiles track
 220478/500000: episode: 230, duration: 57.414s, episode steps: 1000, steps per second:  17, episode reward:  1.961, mean reward:  0.002 [-0.100,  7.743], mean action: 2.079 [0.000, 4.000],  loss: 0.198510, mae: 15.168444, mean_q: 19.053498
Track generation: 1080..1354 -> 274-tiles track
 221135/500000: episode: 231, duration: 38.175s, episode steps: 657, steps per second:  17, episode reward: -114.318, mean reward: -0.174 [-100.000,  7.226], mean action: 1.875 [0.000, 4.000],  loss: 0.207851, mae: 15.035526, mean_q: 18.895152
Track generation: 1258..1576 -> 318-tiles track
 222135/500000: episode: 232, duration: 59.837s, episode steps: 1000, steps per second:  17, episode reward: -36.909, mean reward: -0.037 [-0.100,  6.209], mean action: 2.013 [0.000, 4.000],  loss: 0.198828, mae: 15.053624, mean_q: 18.911426
Track generation: 997..1258 -> 261-tiles track
 223135/500000: episode: 233, duration: 59.826s, episode steps: 1000, steps per second:  17, episode reward:  3.846, mean reward:  0.004 [-0.100,  7.592], mean action: 2.054 [0.000, 4.000],  loss: 0.219951, mae: 15.017946, mean_q: 18.866720
Track generation: 1291..1618 -> 327-tiles track
 224135/500000: episode: 234, duration: 59.800s, episode steps: 1000, steps per second:  17, episode reward: -47.853, mean reward: -0.048 [-0.100,  6.035], mean action: 1.882 [0.000, 4.000],  loss: 0.228830, mae: 15.046410, mean_q: 18.896418
Track generation: 1178..1476 -> 298-tiles track
 225135/500000: episode: 235, duration: 59.922s, episode steps: 1000, steps per second:  17, episode reward: -32.660, mean reward: -0.033 [-0.100,  6.634], mean action: 2.181 [0.000, 4.000],  loss: 0.227709, mae: 15.061900, mean_q: 18.933809
Track generation: 1160..1454 -> 294-tiles track
 225406/500000: episode: 236, duration: 16.573s, episode steps: 271, steps per second:  16, episode reward: -82.631, mean reward: -0.305 [-100.000,  6.726], mean action: 1.742 [0.000, 4.000],  loss: 0.226211, mae: 15.177834, mean_q: 19.066171
Track generation: 1132..1419 -> 287-tiles track
 226406/500000: episode: 237, duration: 60.309s, episode steps: 1000, steps per second:  17, episode reward: -51.049, mean reward: -0.051 [-0.100,  6.893], mean action: 2.317 [0.000, 4.000],  loss: 0.217854, mae: 15.029647, mean_q: 18.877591
Track generation: 1156..1449 -> 293-tiles track
 227406/500000: episode: 238, duration: 60.508s, episode steps: 1000, steps per second:  17, episode reward: -48.630, mean reward: -0.049 [-0.100,  6.749], mean action: 2.122 [0.000, 4.000],  loss: 0.209857, mae: 15.063236, mean_q: 18.930100
Track generation: 1188..1489 -> 301-tiles track
 228406/500000: episode: 239, duration: 59.835s, episode steps: 1000, steps per second:  17, episode reward: 26.667, mean reward:  0.027 [-0.100,  6.567], mean action: 1.822 [0.000, 4.000],  loss: 0.216564, mae: 15.026230, mean_q: 18.871625
Track generation: 1152..1444 -> 292-tiles track
 229406/500000: episode: 240, duration: 60.039s, episode steps: 1000, steps per second:  17, episode reward: -3.780, mean reward: -0.004 [-0.100,  6.773], mean action: 2.376 [0.000, 4.000],  loss: 0.190994, mae: 15.054154, mean_q: 18.920228
Track generation: 1164..1459 -> 295-tiles track
 230406/500000: episode: 241, duration: 59.870s, episode steps: 1000, steps per second:  17, episode reward: -11.565, mean reward: -0.012 [-0.100,  6.703], mean action: 1.794 [0.000, 4.000],  loss: 0.216469, mae: 14.984734, mean_q: 18.825176
Track generation: 1332..1669 -> 337-tiles track
 231406/500000: episode: 242, duration: 61.030s, episode steps: 1000, steps per second:  16, episode reward: -31.548, mean reward: -0.032 [-0.100,  5.852], mean action: 3.560 [0.000, 4.000],  loss: 0.211829, mae: 14.900601, mean_q: 18.708531
Track generation: 1155..1448 -> 293-tiles track
 232406/500000: episode: 243, duration: 60.097s, episode steps: 1000, steps per second:  17, episode reward: 19.863, mean reward:  0.020 [-0.100,  6.749], mean action: 2.503 [0.000, 4.000],  loss: 0.204802, mae: 14.990972, mean_q: 18.841251
Track generation: 1331..1668 -> 337-tiles track
 233406/500000: episode: 244, duration: 61.699s, episode steps: 1000, steps per second:  16, episode reward: -13.690, mean reward: -0.014 [-0.100,  5.852], mean action: 1.792 [0.000, 4.000],  loss: 0.218514, mae: 14.956555, mean_q: 18.809081
Track generation: 1118..1402 -> 284-tiles track
 234406/500000: episode: 245, duration: 61.640s, episode steps: 1000, steps per second:  16, episode reward: -64.664, mean reward: -0.065 [-0.100,  6.967], mean action: 1.940 [0.000, 4.000],  loss: 0.210394, mae: 14.939010, mean_q: 18.755901
Track generation: 1137..1425 -> 288-tiles track
 235406/500000: episode: 246, duration: 60.678s, episode steps: 1000, steps per second:  16, episode reward: 39.373, mean reward:  0.039 [-0.100,  6.869], mean action: 1.648 [0.000, 4.000],  loss: 0.211779, mae: 14.981321, mean_q: 18.829960
Track generation: 1282..1607 -> 325-tiles track
 236406/500000: episode: 247, duration: 61.583s, episode steps: 1000, steps per second:  16, episode reward: -41.358, mean reward: -0.041 [-0.100,  6.073], mean action: 1.833 [0.000, 4.000],  loss: 0.219663, mae: 14.974049, mean_q: 18.824651
Track generation: 1294..1622 -> 328-tiles track
 237406/500000: episode: 248, duration: 61.351s, episode steps: 1000, steps per second:  16, episode reward: -14.373, mean reward: -0.014 [-0.100,  6.016], mean action: 1.750 [0.000, 4.000],  loss: 0.202490, mae: 14.949252, mean_q: 18.798749
Track generation: 1176..1474 -> 298-tiles track
 238406/500000: episode: 249, duration: 60.382s, episode steps: 1000, steps per second:  17, episode reward: -83.165, mean reward: -0.083 [-0.100,  6.634], mean action: 2.881 [0.000, 4.000],  loss: 0.186095, mae: 14.923478, mean_q: 18.757897
Track generation: 1220..1538 -> 318-tiles track
 239406/500000: episode: 250, duration: 62.123s, episode steps: 1000, steps per second:  16, episode reward: -17.981, mean reward: -0.018 [-0.100,  6.209], mean action: 2.646 [0.000, 4.000],  loss: 0.192103, mae: 15.019603, mean_q: 18.874650
Track generation: 1051..1318 -> 267-tiles track
 240406/500000: episode: 251, duration: 61.120s, episode steps: 1000, steps per second:  16, episode reward: 155.639, mean reward:  0.156 [-0.100,  7.419], mean action: 1.740 [0.000, 4.000],  loss: 0.226621, mae: 15.054316, mean_q: 18.920882
Track generation: 1112..1403 -> 291-tiles track
 241406/500000: episode: 252, duration: 62.386s, episode steps: 1000, steps per second:  16, episode reward: -6.897, mean reward: -0.007 [-0.100,  6.797], mean action: 2.556 [0.000, 4.000],  loss: 0.266862, mae: 15.072516, mean_q: 18.939310
Track generation: 1124..1409 -> 285-tiles track
 242406/500000: episode: 253, duration: 62.031s, episode steps: 1000, steps per second:  16, episode reward: -61.268, mean reward: -0.061 [-0.100,  6.942], mean action: 2.164 [0.000, 4.000],  loss: 0.248646, mae: 15.023129, mean_q: 18.882300
Track generation: 1184..1484 -> 300-tiles track
 243406/500000: episode: 254, duration: 61.766s, episode steps: 1000, steps per second:  16, episode reward: 30.435, mean reward:  0.030 [-0.100,  6.589], mean action: 1.856 [0.000, 4.000],  loss: 0.216475, mae: 15.009945, mean_q: 18.874244
Track generation: 1039..1303 -> 264-tiles track
 244406/500000: episode: 255, duration: 61.353s, episode steps: 1000, steps per second:  16, episode reward: 86.312, mean reward:  0.086 [-0.100,  7.505], mean action: 1.499 [0.000, 4.000],  loss: 0.228006, mae: 15.070445, mean_q: 18.938287
Track generation: 1224..1534 -> 310-tiles track
 245406/500000: episode: 256, duration: 61.912s, episode steps: 1000, steps per second:  16, episode reward: -54.693, mean reward: -0.055 [-0.100,  6.372], mean action: 1.864 [0.000, 4.000],  loss: 0.215260, mae: 15.062197, mean_q: 18.938702
Track generation: 1103..1383 -> 280-tiles track
 246406/500000: episode: 257, duration: 58.983s, episode steps: 1000, steps per second:  17, episode reward: -46.237, mean reward: -0.046 [-0.100,  7.068], mean action: 1.950 [0.000, 4.000],  loss: 0.214570, mae: 15.081561, mean_q: 18.964176
Track generation: 1122..1407 -> 285-tiles track
 247406/500000: episode: 258, duration: 61.532s, episode steps: 1000, steps per second:  16, episode reward: -57.746, mean reward: -0.058 [-0.100,  6.942], mean action: 1.894 [0.000, 4.000],  loss: 0.223195, mae: 15.022884, mean_q: 18.878266
Track generation: 1339..1678 -> 339-tiles track
 248406/500000: episode: 259, duration: 63.693s, episode steps: 1000, steps per second:  16, episode reward: -37.870, mean reward: -0.038 [-0.100,  5.817], mean action: 2.027 [0.000, 4.000],  loss: 0.218453, mae: 15.065771, mean_q: 18.955472
Track generation: 1225..1541 -> 316-tiles track
 248827/500000: episode: 260, duration: 25.968s, episode steps: 421, steps per second:  16, episode reward: -110.254, mean reward: -0.262 [-100.000,  6.249], mean action: 1.466 [0.000, 4.000],  loss: 0.210366, mae: 14.951542, mean_q: 18.802736
Track generation: 1223..1533 -> 310-tiles track
 249267/500000: episode: 261, duration: 27.332s, episode steps: 440, steps per second:  16, episode reward: -88.884, mean reward: -0.202 [-100.000,  6.372], mean action: 1.793 [0.000, 4.000],  loss: 0.205053, mae: 15.152667, mean_q: 19.060965
Track generation: 944..1185 -> 241-tiles track
 249687/500000: episode: 262, duration: 25.943s, episode steps: 420, steps per second:  16, episode reward: -79.400, mean reward: -0.189 [-100.000,  8.233], mean action: 1.379 [0.000, 4.000],  loss: 0.226568, mae: 14.987324, mean_q: 18.821473
Track generation: 1232..1547 -> 315-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1212..1519 -> 307-tiles track
 250687/500000: episode: 263, duration: 63.140s, episode steps: 1000, steps per second:  16, episode reward: 109.150, mean reward:  0.109 [-0.100,  6.436], mean action: 1.710 [0.000, 4.000],  loss: 0.203404, mae: 15.038737, mean_q: 18.895362
Track generation: 1195..1498 -> 303-tiles track
 250938/500000: episode: 264, duration: 15.552s, episode steps: 251, steps per second:  16, episode reward: -91.887, mean reward: -0.366 [-100.000,  6.523], mean action: 1.873 [0.000, 4.000],  loss: 0.283741, mae: 14.994344, mean_q: 18.840445
Track generation: 1194..1497 -> 303-tiles track
 251938/500000: episode: 265, duration: 61.979s, episode steps: 1000, steps per second:  16, episode reward: -33.775, mean reward: -0.034 [-0.100,  6.523], mean action: 1.693 [0.000, 4.000],  loss: 0.241674, mae: 15.005838, mean_q: 18.852431
Track generation: 1056..1324 -> 268-tiles track
 252167/500000: episode: 266, duration: 13.795s, episode steps: 229, steps per second:  17, episode reward: -55.384, mean reward: -0.242 [-100.000,  7.391], mean action: 1.825 [0.000, 4.000],  loss: 0.247144, mae: 14.957256, mean_q: 18.798391
Track generation: 1219..1528 -> 309-tiles track
 252653/500000: episode: 267, duration: 30.624s, episode steps: 486, steps per second:  16, episode reward: -80.318, mean reward: -0.165 [-100.000,  6.394], mean action: 1.547 [0.000, 4.000],  loss: 0.238629, mae: 15.046807, mean_q: 18.912763
Track generation: 1256..1575 -> 319-tiles track
 253653/500000: episode: 268, duration: 62.267s, episode steps: 1000, steps per second:  16, episode reward: 132.704, mean reward:  0.133 [-0.100,  6.189], mean action: 1.715 [0.000, 4.000],  loss: 0.230076, mae: 14.977992, mean_q: 18.816520
Track generation: 1180..1479 -> 299-tiles track
 254653/500000: episode: 269, duration: 62.648s, episode steps: 1000, steps per second:  16, episode reward: 77.852, mean reward:  0.078 [-0.100,  6.611], mean action: 1.757 [0.000, 4.000],  loss: 0.239335, mae: 14.971423, mean_q: 18.794378
Track generation: 1058..1332 -> 274-tiles track
 255080/500000: episode: 270, duration: 26.664s, episode steps: 427, steps per second:  16, episode reward: -18.058, mean reward: -0.042 [-100.000,  7.226], mean action: 2.155 [0.000, 4.000],  loss: 0.222744, mae: 15.000349, mean_q: 18.862801
Track generation: 1205..1511 -> 306-tiles track
 256080/500000: episode: 271, duration: 62.544s, episode steps: 1000, steps per second:  16, episode reward: -63.934, mean reward: -0.064 [-0.100,  6.457], mean action: 1.714 [0.000, 4.000],  loss: 0.226383, mae: 15.033212, mean_q: 18.901808
Track generation: 1024..1289 -> 265-tiles track
 257080/500000: episode: 272, duration: 61.510s, episode steps: 1000, steps per second:  16, episode reward:  6.061, mean reward:  0.006 [-0.100,  7.476], mean action: 2.190 [0.000, 4.000],  loss: 0.205248, mae: 15.036875, mean_q: 18.889473
Track generation: 1054..1321 -> 267-tiles track
 257367/500000: episode: 273, duration: 18.074s, episode steps: 287, steps per second:  16, episode reward: -91.006, mean reward: -0.317 [-100.000,  7.419], mean action: 1.868 [0.000, 4.000],  loss: 0.217998, mae: 14.994844, mean_q: 18.846471
Track generation: 1204..1509 -> 305-tiles track
 258367/500000: episode: 274, duration: 63.060s, episode steps: 1000, steps per second:  16, episode reward: 143.421, mean reward:  0.143 [-0.100,  6.479], mean action: 2.206 [0.000, 4.000],  loss: 0.228182, mae: 14.964407, mean_q: 18.798070
Track generation: 1236..1549 -> 313-tiles track
 259367/500000: episode: 275, duration: 62.403s, episode steps: 1000, steps per second:  16, episode reward: 18.590, mean reward:  0.019 [-0.100,  6.310], mean action: 1.830 [0.000, 4.000],  loss: 0.200099, mae: 15.017307, mean_q: 18.874156
Track generation: 1028..1289 -> 261-tiles track
 260367/500000: episode: 276, duration: 60.916s, episode steps: 1000, steps per second:  16, episode reward: 34.615, mean reward:  0.035 [-0.100,  7.592], mean action: 2.246 [0.000, 4.000],  loss: 0.222121, mae: 14.983797, mean_q: 18.817893
Track generation: 1186..1487 -> 301-tiles track
 261367/500000: episode: 277, duration: 63.088s, episode steps: 1000, steps per second:  16, episode reward: -40.000, mean reward: -0.040 [-0.100,  6.567], mean action: 2.778 [0.000, 4.000],  loss: 0.224644, mae: 14.915333, mean_q: 18.748112
Track generation: 1184..1484 -> 300-tiles track
 262367/500000: episode: 278, duration: 63.150s, episode steps: 1000, steps per second:  16, episode reward: 33.779, mean reward:  0.034 [-0.100,  6.589], mean action: 1.478 [0.000, 4.000],  loss: 0.218695, mae: 14.914379, mean_q: 18.752468
Track generation: 1215..1523 -> 308-tiles track
 262607/500000: episode: 279, duration: 15.083s, episode steps: 240, steps per second:  16, episode reward: -75.040, mean reward: -0.313 [-100.000,  6.415], mean action: 1.804 [0.000, 4.000],  loss: 0.217935, mae: 14.821441, mean_q: 18.650562
Track generation: 1028..1289 -> 261-tiles track
 263607/500000: episode: 280, duration: 62.370s, episode steps: 1000, steps per second:  16, episode reward: 188.462, mean reward:  0.188 [-0.100,  7.592], mean action: 1.709 [0.000, 4.000],  loss: 0.224486, mae: 14.895888, mean_q: 18.729881
Track generation: 1127..1413 -> 286-tiles track
 264607/500000: episode: 281, duration: 62.892s, episode steps: 1000, steps per second:  16, episode reward: -54.386, mean reward: -0.054 [-0.100,  6.918], mean action: 2.189 [0.000, 4.000],  loss: 0.255389, mae: 14.946278, mean_q: 18.764407
Track generation: 1085..1360 -> 275-tiles track
 265518/500000: episode: 282, duration: 57.231s, episode steps: 911, steps per second:  16, episode reward: -92.460, mean reward: -0.101 [-100.000,  7.199], mean action: 1.726 [0.000, 4.000],  loss: 0.246882, mae: 14.890828, mean_q: 18.696640
Track generation: 1135..1430 -> 295-tiles track
 265941/500000: episode: 283, duration: 26.890s, episode steps: 423, steps per second:  16, episode reward: -6.146, mean reward: -0.015 [-100.000,  6.703], mean action: 1.953 [0.000, 4.000],  loss: 0.237623, mae: 14.909314, mean_q: 18.734673
Track generation: 1187..1488 -> 301-tiles track
 266941/500000: episode: 284, duration: 63.044s, episode steps: 1000, steps per second:  16, episode reward: -20.000, mean reward: -0.020 [-0.100,  6.567], mean action: 1.799 [0.000, 4.000],  loss: 0.208139, mae: 14.908954, mean_q: 18.746751
Track generation: 1139..1428 -> 289-tiles track
 267941/500000: episode: 285, duration: 62.841s, episode steps: 1000, steps per second:  16, episode reward: -16.667, mean reward: -0.017 [-0.100,  6.844], mean action: 2.294 [0.000, 4.000],  loss: 0.226398, mae: 14.924979, mean_q: 18.756680
Track generation: 1152..1444 -> 292-tiles track
 268812/500000: episode: 286, duration: 54.969s, episode steps: 871, steps per second:  16, episode reward: -111.399, mean reward: -0.128 [-100.000,  6.773], mean action: 1.666 [0.000, 4.000],  loss: 0.218063, mae: 14.918195, mean_q: 18.754949
Track generation: 992..1248 -> 256-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1193..1494 -> 301-tiles track
 269812/500000: episode: 287, duration: 63.598s, episode steps: 1000, steps per second:  16, episode reward: -33.333, mean reward: -0.033 [-0.100,  6.567], mean action: 1.692 [0.000, 4.000],  loss: 0.216550, mae: 14.927252, mean_q: 18.769096
Track generation: 1159..1453 -> 294-tiles track
 270812/500000: episode: 288, duration: 63.875s, episode steps: 1000, steps per second:  16, episode reward: -24.915, mean reward: -0.025 [-0.100,  6.726], mean action: 1.457 [0.000, 4.000],  loss: 0.189296, mae: 14.754530, mean_q: 18.556116
Track generation: 1196..1499 -> 303-tiles track
 271783/500000: episode: 289, duration: 61.350s, episode steps: 971, steps per second:  16, episode reward: -24.815, mean reward: -0.026 [-100.000,  6.523], mean action: 1.526 [0.000, 4.000],  loss: 0.237312, mae: 14.721308, mean_q: 18.502052
Track generation: 1171..1469 -> 298-tiles track
 272783/500000: episode: 290, duration: 64.130s, episode steps: 1000, steps per second:  16, episode reward: 24.579, mean reward:  0.025 [-0.100,  6.634], mean action: 1.864 [0.000, 4.000],  loss: 0.264824, mae: 14.797517, mean_q: 18.587427
Track generation: 1182..1490 -> 308-tiles track
 273783/500000: episode: 291, duration: 64.244s, episode steps: 1000, steps per second:  16, episode reward: 88.925, mean reward:  0.089 [-0.100,  6.415], mean action: 2.167 [0.000, 4.000],  loss: 0.217171, mae: 14.763748, mean_q: 18.543318
Track generation: 1115..1398 -> 283-tiles track
 274783/500000: episode: 292, duration: 64.997s, episode steps: 1000, steps per second:  15, episode reward: -32.624, mean reward: -0.033 [-0.100,  6.992], mean action: 1.815 [0.000, 4.000],  loss: 0.245073, mae: 14.812438, mean_q: 18.620139
Track generation: 1083..1358 -> 275-tiles track
 275783/500000: episode: 293, duration: 64.130s, episode steps: 1000, steps per second:  16, episode reward: -52.555, mean reward: -0.053 [-0.100,  7.199], mean action: 2.058 [0.000, 4.000],  loss: 0.227859, mae: 14.796628, mean_q: 18.575569
Track generation: 1144..1434 -> 290-tiles track
 276783/500000: episode: 294, duration: 63.985s, episode steps: 1000, steps per second:  16, episode reward: 138.754, mean reward:  0.139 [-0.100,  6.820], mean action: 1.621 [0.000, 4.000],  loss: 0.207249, mae: 14.768928, mean_q: 18.557544
Track generation: 1175..1475 -> 300-tiles track
 277783/500000: episode: 295, duration: 63.863s, episode steps: 1000, steps per second:  16, episode reward: -19.732, mean reward: -0.020 [-0.100,  6.589], mean action: 1.721 [0.000, 4.000],  loss: 0.234610, mae: 14.862514, mean_q: 18.666789
Track generation: 1116..1399 -> 283-tiles track
 278783/500000: episode: 296, duration: 64.797s, episode steps: 1000, steps per second:  15, episode reward: -60.993, mean reward: -0.061 [-0.100,  6.992], mean action: 1.451 [0.000, 4.000],  loss: 0.211191, mae: 14.790907, mean_q: 18.579293
Track generation: 1081..1355 -> 274-tiles track
 279783/500000: episode: 297, duration: 64.451s, episode steps: 1000, steps per second:  16, episode reward: 64.835, mean reward:  0.065 [-0.100,  7.226], mean action: 1.839 [0.000, 4.000],  loss: 0.242138, mae: 14.811139, mean_q: 18.623981
Track generation: 1086..1362 -> 276-tiles track
 280783/500000: episode: 298, duration: 65.291s, episode steps: 1000, steps per second:  15, episode reward: 103.636, mean reward:  0.104 [-0.100,  7.173], mean action: 1.299 [0.000, 4.000],  loss: 0.214233, mae: 14.764849, mean_q: 18.556352
Track generation: 1236..1549 -> 313-tiles track
 281783/500000: episode: 299, duration: 67.088s, episode steps: 1000, steps per second:  15, episode reward: -32.692, mean reward: -0.033 [-0.100,  6.310], mean action: 2.019 [0.000, 4.000],  loss: 0.244143, mae: 14.772700, mean_q: 18.561411
Track generation: 1133..1420 -> 287-tiles track
 282783/500000: episode: 300, duration: 65.545s, episode steps: 1000, steps per second:  15, episode reward: -51.049, mean reward: -0.051 [-0.100,  6.893], mean action: 2.182 [0.000, 4.000],  loss: 0.242238, mae: 14.826422, mean_q: 18.632273
Track generation: 1020..1282 -> 262-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1130..1417 -> 287-tiles track
 283783/500000: episode: 301, duration: 65.048s, episode steps: 1000, steps per second:  15, episode reward: 78.322, mean reward:  0.078 [-0.100,  6.893], mean action: 1.976 [0.000, 4.000],  loss: 0.220544, mae: 14.766532, mean_q: 18.570457
Track generation: 1203..1508 -> 305-tiles track
 284783/500000: episode: 302, duration: 66.119s, episode steps: 1000, steps per second:  15, episode reward: -34.211, mean reward: -0.034 [-0.100,  6.479], mean action: 1.450 [0.000, 4.000],  loss: 0.226536, mae: 14.750885, mean_q: 18.546006
Track generation: 1054..1307 -> 253-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1223..1533 -> 310-tiles track
 285783/500000: episode: 303, duration: 66.178s, episode steps: 1000, steps per second:  15, episode reward: 42.395, mean reward:  0.042 [-0.100,  6.372], mean action: 2.006 [0.000, 4.000],  loss: 0.222933, mae: 14.760260, mean_q: 18.550974
Track generation: 1203..1508 -> 305-tiles track
 286783/500000: episode: 304, duration: 64.877s, episode steps: 1000, steps per second:  15, episode reward: 74.342, mean reward:  0.074 [-0.100,  6.479], mean action: 1.546 [0.000, 4.000],  loss: 0.225807, mae: 14.706208, mean_q: 18.484208
Track generation: 1171..1468 -> 297-tiles track
 287450/500000: episode: 305, duration: 42.854s, episode steps: 667, steps per second:  16, episode reward: -4.438, mean reward: -0.007 [-100.000,  6.657], mean action: 1.727 [0.000, 4.000],  loss: 0.248592, mae: 14.803495, mean_q: 18.622070
Track generation: 1123..1408 -> 285-tiles track
 288450/500000: episode: 306, duration: 64.885s, episode steps: 1000, steps per second:  15, episode reward: 47.887, mean reward:  0.048 [-0.100,  6.942], mean action: 2.201 [0.000, 4.000],  loss: 0.226418, mae: 14.794544, mean_q: 18.606801
Track generation: 1317..1650 -> 333-tiles track
 288935/500000: episode: 307, duration: 33.015s, episode steps: 485, steps per second:  15, episode reward: -67.075, mean reward: -0.138 [-100.000,  5.924], mean action: 1.755 [0.000, 4.000],  loss: 0.283010, mae: 14.829839, mean_q: 18.636104
Track generation: 1172..1469 -> 297-tiles track
 289935/500000: episode: 308, duration: 66.176s, episode steps: 1000, steps per second:  15, episode reward: 52.027, mean reward:  0.052 [-0.100,  6.657], mean action: 1.736 [0.000, 4.000],  loss: 0.264120, mae: 14.850441, mean_q: 18.676440
Track generation: 1201..1505 -> 304-tiles track
 290935/500000: episode: 309, duration: 66.490s, episode steps: 1000, steps per second:  15, episode reward: -27.393, mean reward: -0.027 [-0.100,  6.501], mean action: 1.635 [0.000, 4.000],  loss: 0.203692, mae: 14.673476, mean_q: 18.447559
Track generation: 1088..1364 -> 276-tiles track
 291935/500000: episode: 310, duration: 66.631s, episode steps: 1000, steps per second:  15, episode reward: 23.636, mean reward:  0.024 [-0.100,  7.173], mean action: 1.300 [0.000, 4.000],  loss: 0.203874, mae: 14.707672, mean_q: 18.475126
Track generation: 1135..1424 -> 289-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1045..1316 -> 271-tiles track
 292935/500000: episode: 311, duration: 66.519s, episode steps: 1000, steps per second:  15, episode reward: -70.370, mean reward: -0.070 [-0.100,  7.307], mean action: 2.331 [0.000, 4.000],  loss: 0.243954, mae: 14.719217, mean_q: 18.483188
Track generation: 1335..1673 -> 338-tiles track
 293935/500000: episode: 312, duration: 66.553s, episode steps: 1000, steps per second:  15, episode reward: -64.392, mean reward: -0.064 [-0.100,  5.835], mean action: 1.631 [0.000, 4.000],  loss: 0.208885, mae: 14.697359, mean_q: 18.468875
Track generation: 1094..1378 -> 284-tiles track
 294260/500000: episode: 313, duration: 21.403s, episode steps: 325, steps per second:  15, episode reward: -5.192, mean reward: -0.016 [-100.000,  6.967], mean action: 1.206 [0.000, 4.000],  loss: 0.232748, mae: 14.754957, mean_q: 18.529618
Track generation: 1156..1449 -> 293-tiles track
 295260/500000: episode: 314, duration: 66.503s, episode steps: 1000, steps per second:  15, episode reward: 57.534, mean reward:  0.058 [-0.100,  6.749], mean action: 1.933 [0.000, 4.000],  loss: 0.264018, mae: 14.768045, mean_q: 18.543378
Track generation: 1096..1374 -> 278-tiles track
 296260/500000: episode: 315, duration: 66.969s, episode steps: 1000, steps per second:  15, episode reward: 80.505, mean reward:  0.081 [-0.100,  7.120], mean action: 1.856 [0.000, 4.000],  loss: 0.215882, mae: 14.683725, mean_q: 18.454256
Track generation: 1187..1488 -> 301-tiles track
 297260/500000: episode: 316, duration: 66.268s, episode steps: 1000, steps per second:  15, episode reward: 23.333, mean reward:  0.023 [-0.100,  6.567], mean action: 1.629 [0.000, 4.000],  loss: 0.220747, mae: 14.653110, mean_q: 18.420609
Track generation: 1224..1534 -> 310-tiles track
 298260/500000: episode: 317, duration: 66.739s, episode steps: 1000, steps per second:  15, episode reward: 165.372, mean reward:  0.165 [-0.100,  6.372], mean action: 1.890 [0.000, 4.000],  loss: 0.233119, mae: 14.711268, mean_q: 18.479746
Track generation: 1091..1368 -> 277-tiles track
 299260/500000: episode: 318, duration: 66.667s, episode steps: 1000, steps per second:  15, episode reward: 37.681, mean reward:  0.038 [-0.100,  7.146], mean action: 1.708 [0.000, 4.000],  loss: 0.213667, mae: 14.722420, mean_q: 18.503995
Track generation: 1026..1292 -> 266-tiles track
 299581/500000: episode: 319, duration: 22.120s, episode steps: 321, steps per second:  15, episode reward:  3.849, mean reward:  0.012 [-100.000,  7.447], mean action: 1.907 [0.000, 4.000],  loss: 0.245747, mae: 14.717879, mean_q: 18.475318
Track generation: 1179..1478 -> 299-tiles track
 300581/500000: episode: 320, duration: 67.307s, episode steps: 1000, steps per second:  15, episode reward: 44.295, mean reward:  0.044 [-0.100,  6.611], mean action: 2.289 [0.000, 4.000],  loss: 0.236621, mae: 14.648576, mean_q: 18.402892
Track generation: 1164..1459 -> 295-tiles track
 301581/500000: episode: 321, duration: 66.451s, episode steps: 1000, steps per second:  15, episode reward: -79.592, mean reward: -0.080 [-0.100,  6.703], mean action: 2.003 [0.000, 4.000],  loss: 0.270224, mae: 14.668420, mean_q: 18.429483
Track generation: 1262..1582 -> 320-tiles track
 302581/500000: episode: 322, duration: 66.130s, episode steps: 1000, steps per second:  15, episode reward: -31.034, mean reward: -0.031 [-0.100,  6.170], mean action: 1.499 [0.000, 4.000],  loss: 0.256805, mae: 14.571786, mean_q: 18.310053
Track generation: 1171..1468 -> 297-tiles track
 303581/500000: episode: 323, duration: 66.257s, episode steps: 1000, steps per second:  15, episode reward: 65.541, mean reward:  0.066 [-0.100,  6.657], mean action: 2.066 [0.000, 4.000],  loss: 0.245843, mae: 14.628647, mean_q: 18.374459
Track generation: 1108..1389 -> 281-tiles track
 303856/500000: episode: 324, duration: 18.063s, episode steps: 275, steps per second:  15, episode reward: -88.114, mean reward: -0.320 [-100.000,  7.043], mean action: 1.705 [0.000, 4.000],  loss: 0.201726, mae: 14.585996, mean_q: 18.336060
Track generation: 1235..1548 -> 313-tiles track
 304856/500000: episode: 325, duration: 67.776s, episode steps: 1000, steps per second:  15, episode reward: 140.385, mean reward:  0.140 [-0.100,  6.310], mean action: 1.561 [0.000, 4.000],  loss: 0.208737, mae: 14.591895, mean_q: 18.340530
Track generation: 1055..1328 -> 273-tiles track
 305604/500000: episode: 326, duration: 50.863s, episode steps: 748, steps per second:  15, episode reward: -104.847, mean reward: -0.140 [-100.000, 10.929], mean action: 2.151 [0.000, 4.000],  loss: 0.211146, mae: 14.675722, mean_q: 18.434165
Track generation: 1119..1403 -> 284-tiles track
 306604/500000: episode: 327, duration: 67.777s, episode steps: 1000, steps per second:  15, episode reward: 214.488, mean reward:  0.214 [-0.100,  6.967], mean action: 1.974 [0.000, 4.000],  loss: 0.222034, mae: 14.640576, mean_q: 18.394158
Track generation: 1179..1478 -> 299-tiles track
 307604/500000: episode: 328, duration: 68.237s, episode steps: 1000, steps per second:  15, episode reward: 74.497, mean reward:  0.074 [-0.100,  6.611], mean action: 1.832 [0.000, 4.000],  loss: 0.229286, mae: 14.669340, mean_q: 18.435927
Track generation: 1028..1290 -> 262-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1065..1335 -> 270-tiles track
 308604/500000: episode: 329, duration: 66.139s, episode steps: 1000, steps per second:  15, episode reward: -33.086, mean reward: -0.033 [-0.100,  7.335], mean action: 1.743 [0.000, 4.000],  loss: 0.272324, mae: 14.668711, mean_q: 18.420382
Track generation: 1306..1637 -> 331-tiles track
 309604/500000: episode: 330, duration: 67.944s, episode steps: 1000, steps per second:  15, episode reward: 12.121, mean reward:  0.012 [-0.100,  5.961], mean action: 1.761 [0.000, 4.000],  loss: 0.206724, mae: 14.675586, mean_q: 18.446285
Track generation: 1131..1418 -> 287-tiles track
 310604/500000: episode: 331, duration: 69.000s, episode steps: 1000, steps per second:  14, episode reward: -26.573, mean reward: -0.027 [-0.100,  6.893], mean action: 1.858 [0.000, 4.000],  loss: 0.218017, mae: 14.595895, mean_q: 18.351801
Track generation: 1192..1494 -> 302-tiles track
 311604/500000: episode: 332, duration: 68.547s, episode steps: 1000, steps per second:  15, episode reward: 122.591, mean reward:  0.123 [-0.100,  6.545], mean action: 2.095 [0.000, 4.000],  loss: 0.227375, mae: 14.618264, mean_q: 18.375330
Track generation: 1147..1438 -> 291-tiles track
 312604/500000: episode: 333, duration: 68.286s, episode steps: 1000, steps per second:  15, episode reward: 27.586, mean reward:  0.028 [-0.100,  6.797], mean action: 1.842 [0.000, 4.000],  loss: 0.203042, mae: 14.610807, mean_q: 18.374389
Track generation: 1101..1381 -> 280-tiles track
 313604/500000: episode: 334, duration: 67.106s, episode steps: 1000, steps per second:  15, episode reward: 68.459, mean reward:  0.068 [-0.100,  7.068], mean action: 1.488 [0.000, 4.000],  loss: 0.263184, mae: 14.632321, mean_q: 18.378211
Track generation: 1100..1378 -> 278-tiles track
 314604/500000: episode: 335, duration: 69.196s, episode steps: 1000, steps per second:  14, episode reward: 239.350, mean reward:  0.239 [-0.100,  7.120], mean action: 1.363 [0.000, 4.000],  loss: 0.234193, mae: 14.625681, mean_q: 18.389029
Track generation: 1027..1288 -> 261-tiles track
 315604/500000: episode: 336, duration: 68.673s, episode steps: 1000, steps per second:  15, episode reward: 53.846, mean reward:  0.054 [-0.100,  7.592], mean action: 1.931 [0.000, 4.000],  loss: 0.258535, mae: 14.647927, mean_q: 18.394296
Track generation: 1011..1272 -> 261-tiles track
 316604/500000: episode: 337, duration: 68.429s, episode steps: 1000, steps per second:  15, episode reward: 57.692, mean reward:  0.058 [-0.100,  7.592], mean action: 1.755 [0.000, 4.000],  loss: 0.254286, mae: 14.612533, mean_q: 18.359714
Track generation: 1069..1340 -> 271-tiles track
 317604/500000: episode: 338, duration: 69.035s, episode steps: 1000, steps per second:  14, episode reward: 148.148, mean reward:  0.148 [-0.100,  7.307], mean action: 1.712 [0.000, 4.000],  loss: 0.226821, mae: 14.634315, mean_q: 18.382609
Track generation: 1040..1310 -> 270-tiles track
 318210/500000: episode: 339, duration: 40.337s, episode steps: 606, steps per second:  15, episode reward: -86.151, mean reward: -0.142 [-100.000,  7.335], mean action: 1.617 [0.000, 4.000],  loss: 0.238687, mae: 14.697386, mean_q: 18.456826
Track generation: 1212..1519 -> 307-tiles track
 319210/500000: episode: 340, duration: 69.064s, episode steps: 1000, steps per second:  14, episode reward: 37.255, mean reward:  0.037 [-0.100,  6.436], mean action: 2.641 [0.000, 4.000],  loss: 0.234775, mae: 14.639149, mean_q: 18.380923
Track generation: 1207..1513 -> 306-tiles track
 320210/500000: episode: 341, duration: 68.362s, episode steps: 1000, steps per second:  15, episode reward: 31.148, mean reward:  0.031 [-0.100,  6.457], mean action: 1.300 [0.000, 4.000],  loss: 0.213713, mae: 14.677974, mean_q: 18.437069
Track generation: 1221..1539 -> 318-tiles track
 320807/500000: episode: 342, duration: 42.757s, episode steps: 597, steps per second:  14, episode reward: -27.108, mean reward: -0.045 [-100.000,  6.209], mean action: 2.246 [0.000, 4.000],  loss: 0.228689, mae: 14.601062, mean_q: 18.337487
Track generation: 1140..1429 -> 289-tiles track
 321807/500000: episode: 343, duration: 69.047s, episode steps: 1000, steps per second:  14, episode reward: -6.250, mean reward: -0.006 [-0.100,  6.844], mean action: 1.358 [0.000, 4.000],  loss: 0.235728, mae: 14.619075, mean_q: 18.372194
Track generation: 1109..1391 -> 282-tiles track
 322575/500000: episode: 344, duration: 53.088s, episode steps: 768, steps per second:  14, episode reward: -37.910, mean reward: -0.049 [-100.000,  7.017], mean action: 1.660 [0.000, 4.000],  loss: 0.250054, mae: 14.665975, mean_q: 18.433405
Track generation: 1105..1395 -> 290-tiles track
 323575/500000: episode: 345, duration: 68.907s, episode steps: 1000, steps per second:  15, episode reward: -72.318, mean reward: -0.072 [-0.100,  6.820], mean action: 1.945 [0.000, 4.000],  loss: 0.259471, mae: 14.648241, mean_q: 18.414671
Track generation: 1207..1513 -> 306-tiles track
 324575/500000: episode: 346, duration: 70.115s, episode steps: 1000, steps per second:  14, episode reward: -70.492, mean reward: -0.070 [-0.100,  6.457], mean action: 2.109 [0.000, 4.000],  loss: 0.238713, mae: 14.572491, mean_q: 18.306477
Track generation: 1081..1355 -> 274-tiles track
 325575/500000: episode: 347, duration: 68.247s, episode steps: 1000, steps per second:  15, episode reward: -19.414, mean reward: -0.019 [-0.100,  7.226], mean action: 1.836 [0.000, 4.000],  loss: 0.231713, mae: 14.641953, mean_q: 18.409366
Track generation: 1134..1422 -> 288-tiles track
 325862/500000: episode: 348, duration: 20.203s, episode steps: 287, steps per second:  14, episode reward: -69.367, mean reward: -0.242 [-100.000,  6.869], mean action: 2.143 [0.000, 4.000],  loss: 0.265449, mae: 14.577159, mean_q: 18.306059
Track generation: 1092..1369 -> 277-tiles track
 326862/500000: episode: 349, duration: 68.494s, episode steps: 1000, steps per second:  15, episode reward: -34.783, mean reward: -0.035 [-0.100,  7.146], mean action: 1.868 [0.000, 4.000],  loss: 0.235930, mae: 14.595750, mean_q: 18.341852
Track generation: 1147..1438 -> 291-tiles track
 327862/500000: episode: 350, duration: 67.422s, episode steps: 1000, steps per second:  15, episode reward: -6.897, mean reward: -0.007 [-0.100, 10.245], mean action: 1.963 [0.000, 4.000],  loss: 0.231946, mae: 14.623759, mean_q: 18.372447
Track generation: 1003..1266 -> 263-tiles track
 328862/500000: episode: 351, duration: 67.583s, episode steps: 1000, steps per second:  15, episode reward: 37.405, mean reward:  0.037 [-0.100,  7.534], mean action: 1.403 [0.000, 4.000],  loss: 0.215749, mae: 14.571933, mean_q: 18.316723
Track generation: 1059..1329 -> 270-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1148..1439 -> 291-tiles track
 329862/500000: episode: 352, duration: 69.504s, episode steps: 1000, steps per second:  14, episode reward: 120.690, mean reward:  0.121 [-0.100,  6.797], mean action: 1.873 [0.000, 4.000],  loss: 0.239886, mae: 14.629208, mean_q: 18.370179
Track generation: 879..1108 -> 229-tiles track
 330862/500000: episode: 353, duration: 68.642s, episode steps: 1000, steps per second:  15, episode reward: 97.368, mean reward:  0.097 [-0.100,  8.672], mean action: 1.817 [0.000, 4.000],  loss: 0.278462, mae: 14.585437, mean_q: 18.328212
Track generation: 1155..1447 -> 292-tiles track
 331862/500000: episode: 354, duration: 69.806s, episode steps: 1000, steps per second:  14, episode reward: -45.017, mean reward: -0.045 [-0.100,  6.773], mean action: 1.853 [0.000, 4.000],  loss: 0.237020, mae: 14.585181, mean_q: 18.342921
Track generation: 1232..1544 -> 312-tiles track
 332205/500000: episode: 355, duration: 23.556s, episode steps: 343, steps per second:  15, episode reward: -69.891, mean reward: -0.204 [-100.000,  6.331], mean action: 1.714 [0.000, 4.000],  loss: 0.239235, mae: 14.576978, mean_q: 18.316572
Track generation: 1162..1457 -> 295-tiles track
 333205/500000: episode: 356, duration: 70.548s, episode steps: 1000, steps per second:  14, episode reward: 104.082, mean reward:  0.104 [-0.100,  6.703], mean action: 2.010 [0.000, 4.000],  loss: 0.257510, mae: 14.548004, mean_q: 18.288558
Track generation: 1322..1657 -> 335-tiles track
 333618/500000: episode: 357, duration: 29.076s, episode steps: 413, steps per second:  14, episode reward: -60.362, mean reward: -0.146 [-100.000,  5.888], mean action: 1.973 [0.000, 4.000],  loss: 0.252585, mae: 14.611534, mean_q: 18.358764
Track generation: 1163..1458 -> 295-tiles track
 334618/500000: episode: 358, duration: 69.521s, episode steps: 1000, steps per second:  14, episode reward: 93.878, mean reward:  0.094 [-0.100,  6.703], mean action: 2.009 [0.000, 4.000],  loss: 0.287456, mae: 14.567285, mean_q: 18.298730
Track generation: 1287..1613 -> 326-tiles track
 335618/500000: episode: 359, duration: 70.543s, episode steps: 1000, steps per second:  14, episode reward: -69.231, mean reward: -0.069 [-0.100,  6.054], mean action: 1.921 [0.000, 4.000],  loss: 0.295404, mae: 14.586566, mean_q: 18.321844
Track generation: 1196..1498 -> 302-tiles track
 336151/500000: episode: 360, duration: 37.589s, episode steps: 533, steps per second:  14, episode reward: -83.433, mean reward: -0.157 [-100.000,  6.545], mean action: 1.501 [0.000, 4.000],  loss: 0.273731, mae: 14.577712, mean_q: 18.325396
Track generation: 1116..1399 -> 283-tiles track
 337151/500000: episode: 361, duration: 70.785s, episode steps: 1000, steps per second:  14, episode reward: 304.255, mean reward:  0.304 [-0.100,  6.992], mean action: 1.850 [0.000, 4.000],  loss: 0.292276, mae: 14.632731, mean_q: 18.389007
Track generation: 1051..1327 -> 276-tiles track
 338151/500000: episode: 362, duration: 70.891s, episode steps: 1000, steps per second:  14, episode reward: 30.909, mean reward:  0.031 [-0.100,  7.173], mean action: 1.874 [0.000, 4.000],  loss: 0.270828, mae: 14.589448, mean_q: 18.339216
Track generation: 1099..1378 -> 279-tiles track
 339151/500000: episode: 363, duration: 70.281s, episode steps: 1000, steps per second:  14, episode reward: 15.108, mean reward:  0.015 [-0.100,  7.094], mean action: 1.809 [0.000, 4.000],  loss: 0.254295, mae: 14.562763, mean_q: 18.320768
Track generation: 1017..1282 -> 265-tiles track
 340151/500000: episode: 364, duration: 70.638s, episode steps: 1000, steps per second:  14, episode reward: 66.667, mean reward:  0.067 [-0.100,  7.476], mean action: 1.839 [0.000, 4.000],  loss: 0.238112, mae: 14.567482, mean_q: 18.337515
Track generation: 1164..1459 -> 295-tiles track
 340626/500000: episode: 365, duration: 33.125s, episode steps: 475, steps per second:  14, episode reward: -96.380, mean reward: -0.203 [-100.000,  6.703], mean action: 1.954 [0.000, 4.000],  loss: 0.291418, mae: 14.562739, mean_q: 18.304189
Track generation: 1292..1619 -> 327-tiles track
 341626/500000: episode: 366, duration: 70.731s, episode steps: 1000, steps per second:  14, episode reward: 50.307, mean reward:  0.050 [-0.100,  6.035], mean action: 2.093 [0.000, 4.000],  loss: 0.244824, mae: 14.469071, mean_q: 18.189001
Track generation: 1264..1592 -> 328-tiles track
 342039/500000: episode: 367, duration: 29.657s, episode steps: 413, steps per second:  14, episode reward: -104.503, mean reward: -0.253 [-100.000,  6.016], mean action: 1.993 [0.000, 4.000],  loss: 0.263700, mae: 14.584730, mean_q: 18.368627
Track generation: 1092..1369 -> 277-tiles track
 343039/500000: episode: 368, duration: 71.103s, episode steps: 1000, steps per second:  14, episode reward: 229.710, mean reward:  0.230 [-0.100,  7.146], mean action: 1.826 [0.000, 4.000],  loss: 0.256576, mae: 14.467305, mean_q: 18.200556
Track generation: 1117..1401 -> 284-tiles track
 344039/500000: episode: 369, duration: 69.062s, episode steps: 1000, steps per second:  14, episode reward: 16.608, mean reward:  0.017 [-0.100,  6.967], mean action: 1.968 [0.000, 4.000],  loss: 0.264674, mae: 14.555731, mean_q: 18.303967
Track generation: 1149..1440 -> 291-tiles track
 345039/500000: episode: 370, duration: 71.591s, episode steps: 1000, steps per second:  14, episode reward: -41.379, mean reward: -0.041 [-0.100,  6.797], mean action: 2.339 [0.000, 4.000],  loss: 0.244937, mae: 14.524500, mean_q: 18.262891
Track generation: 1184..1484 -> 300-tiles track
 345748/500000: episode: 371, duration: 51.046s, episode steps: 709, steps per second:  14, episode reward: -117.288, mean reward: -0.165 [-100.000,  6.589], mean action: 2.192 [0.000, 4.000],  loss: 0.321067, mae: 14.423190, mean_q: 18.124933
Track generation: 1149..1440 -> 291-tiles track
 346748/500000: episode: 372, duration: 70.839s, episode steps: 1000, steps per second:  14, episode reward: 341.379, mean reward:  0.341 [-0.100,  6.797], mean action: 1.261 [0.000, 4.000],  loss: 0.244108, mae: 14.501325, mean_q: 18.230611
Track generation: 1019..1282 -> 263-tiles track
 347541/500000: episode: 373, duration: 56.535s, episode steps: 793, steps per second:  14, episode reward: -57.063, mean reward: -0.072 [-100.000,  7.534], mean action: 1.638 [0.000, 4.000],  loss: 0.304078, mae: 14.536710, mean_q: 18.256930
Track generation: 1115..1398 -> 283-tiles track
 348541/500000: episode: 374, duration: 72.534s, episode steps: 1000, steps per second:  14, episode reward: -68.085, mean reward: -0.068 [-0.100,  6.992], mean action: 1.623 [0.000, 4.000],  loss: 0.273330, mae: 14.502913, mean_q: 18.238449
Track generation: 1136..1424 -> 288-tiles track
 349541/500000: episode: 375, duration: 70.458s, episode steps: 1000, steps per second:  14, episode reward: -26.829, mean reward: -0.027 [-0.100,  6.869], mean action: 1.845 [0.000, 4.000],  loss: 0.260656, mae: 14.417869, mean_q: 18.128352
Track generation: 1079..1353 -> 274-tiles track
 350541/500000: episode: 376, duration: 72.288s, episode steps: 1000, steps per second:  14, episode reward: -56.044, mean reward: -0.056 [-0.100,  7.226], mean action: 1.813 [0.000, 4.000],  loss: 0.284700, mae: 14.379657, mean_q: 18.093756
Track generation: 1218..1526 -> 308-tiles track
 351541/500000: episode: 377, duration: 72.484s, episode steps: 1000, steps per second:  14, episode reward: 121.498, mean reward:  0.121 [-0.100,  6.415], mean action: 2.012 [0.000, 4.000],  loss: 0.267371, mae: 14.155377, mean_q: 17.810204
Track generation: 1145..1441 -> 296-tiles track
 352541/500000: episode: 378, duration: 71.481s, episode steps: 1000, steps per second:  14, episode reward: -22.034, mean reward: -0.022 [-0.100,  6.680], mean action: 2.197 [0.000, 4.000],  loss: 0.312421, mae: 14.171737, mean_q: 17.802189
Track generation: 960..1206 -> 246-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1092..1369 -> 277-tiles track
 353541/500000: episode: 379, duration: 70.184s, episode steps: 1000, steps per second:  14, episode reward: 52.174, mean reward:  0.052 [-0.100,  7.146], mean action: 1.866 [0.000, 4.000],  loss: 0.260369, mae: 14.125996, mean_q: 17.757059
Track generation: 1009..1265 -> 256-tiles track
 354541/500000: episode: 380, duration: 69.779s, episode steps: 1000, steps per second:  14, episode reward: -56.863, mean reward: -0.057 [-0.100,  7.743], mean action: 1.951 [0.000, 4.000],  loss: 0.263981, mae: 14.162187, mean_q: 17.806908
Track generation: 1183..1483 -> 300-tiles track
 355207/500000: episode: 381, duration: 47.100s, episode steps: 666, steps per second:  14, episode reward: -96.266, mean reward: -0.145 [-100.000,  6.589], mean action: 1.447 [0.000, 4.000],  loss: 0.251675, mae: 14.097170, mean_q: 17.738650
Track generation: 1147..1446 -> 299-tiles track
 356207/500000: episode: 382, duration: 72.479s, episode steps: 1000, steps per second:  14, episode reward: 235.570, mean reward:  0.236 [-0.100,  6.611], mean action: 1.790 [0.000, 4.000],  loss: 0.258311, mae: 14.148483, mean_q: 17.790806
Track generation: 1112..1394 -> 282-tiles track
 357207/500000: episode: 383, duration: 72.461s, episode steps: 1000, steps per second:  14, episode reward: 85.053, mean reward:  0.085 [-0.100,  7.017], mean action: 1.721 [0.000, 4.000],  loss: 0.241431, mae: 14.163984, mean_q: 17.812490
Track generation: 1020..1287 -> 267-tiles track
 357447/500000: episode: 384, duration: 17.473s, episode steps: 240, steps per second:  14, episode reward: 60.311, mean reward:  0.251 [-100.000,  7.419], mean action: 1.671 [0.000, 4.000],  loss: 0.242244, mae: 14.150872, mean_q: 17.789158
Track generation: 1263..1583 -> 320-tiles track
 358447/500000: episode: 385, duration: 72.421s, episode steps: 1000, steps per second:  14, episode reward: 66.144, mean reward:  0.066 [-0.100,  6.170], mean action: 1.971 [0.000, 4.000],  loss: 0.270487, mae: 14.186067, mean_q: 17.844403
Track generation: 1092..1369 -> 277-tiles track
 359447/500000: episode: 386, duration: 72.751s, episode steps: 1000, steps per second:  14, episode reward: 70.290, mean reward:  0.070 [-0.100,  7.146], mean action: 1.666 [0.000, 4.000],  loss: 0.316390, mae: 14.209246, mean_q: 17.870333
Track generation: 1161..1460 -> 299-tiles track
 359740/500000: episode: 387, duration: 21.252s, episode steps: 293, steps per second:  14, episode reward: -15.106, mean reward: -0.052 [-100.000,  6.611], mean action: 1.625 [0.000, 4.000],  loss: 0.318733, mae: 14.267257, mean_q: 17.935355
Track generation: 1208..1520 -> 312-tiles track
 360740/500000: episode: 388, duration: 73.441s, episode steps: 1000, steps per second:  14, episode reward: 311.576, mean reward:  0.312 [-0.100,  6.331], mean action: 1.859 [0.000, 4.000],  loss: 0.245293, mae: 13.955811, mean_q: 17.540264
Track generation: 1060..1329 -> 269-tiles track
 361740/500000: episode: 389, duration: 70.782s, episode steps: 1000, steps per second:  14, episode reward: -2.985, mean reward: -0.003 [-0.100,  7.363], mean action: 1.635 [0.000, 4.000],  loss: 0.278630, mae: 13.943122, mean_q: 17.534853
Track generation: 1208..1514 -> 306-tiles track
 362740/500000: episode: 390, duration: 74.035s, episode steps: 1000, steps per second:  14, episode reward: -34.426, mean reward: -0.034 [-0.100,  6.457], mean action: 1.513 [0.000, 4.000],  loss: 0.257643, mae: 13.931456, mean_q: 17.522398
Track generation: 1151..1449 -> 298-tiles track
 363322/500000: episode: 391, duration: 42.521s, episode steps: 582, steps per second:  14, episode reward: -121.063, mean reward: -0.208 [-100.000,  6.634], mean action: 1.488 [0.000, 4.000],  loss: 0.301775, mae: 13.846927, mean_q: 17.389651
Track generation: 1127..1413 -> 286-tiles track
 364322/500000: episode: 392, duration: 72.717s, episode steps: 1000, steps per second:  14, episode reward: -71.930, mean reward: -0.072 [-0.100,  6.918], mean action: 2.229 [0.000, 4.000],  loss: 0.281678, mae: 13.956849, mean_q: 17.545564
Track generation: 1201..1514 -> 313-tiles track
 365199/500000: episode: 393, duration: 64.983s, episode steps: 877, steps per second:  13, episode reward: 155.349, mean reward:  0.177 [-100.000,  6.310], mean action: 1.831 [0.000, 4.000],  loss: 0.298249, mae: 13.933357, mean_q: 17.518227
Track generation: 1120..1404 -> 284-tiles track
 366199/500000: episode: 394, duration: 72.069s, episode steps: 1000, steps per second:  14, episode reward: 140.283, mean reward:  0.140 [-0.100,  6.967], mean action: 1.695 [0.000, 4.000],  loss: 0.272331, mae: 13.930836, mean_q: 17.520732
Track generation: 1343..1683 -> 340-tiles track
 367199/500000: episode: 395, duration: 74.271s, episode steps: 1000, steps per second:  13, episode reward: 53.392, mean reward:  0.053 [-0.100,  5.800], mean action: 1.796 [0.000, 4.000],  loss: 0.287192, mae: 13.976690, mean_q: 17.579223
Track generation: 1062..1340 -> 278-tiles track
 368199/500000: episode: 396, duration: 75.251s, episode steps: 1000, steps per second:  13, episode reward: 84.116, mean reward:  0.084 [-0.100,  7.120], mean action: 2.724 [0.000, 4.000],  loss: 0.260502, mae: 13.946896, mean_q: 17.541583
Track generation: 1038..1307 -> 269-tiles track
 369199/500000: episode: 397, duration: 72.849s, episode steps: 1000, steps per second:  14, episode reward: 191.045, mean reward:  0.191 [-0.100,  7.363], mean action: 1.686 [0.000, 4.000],  loss: 0.289256, mae: 13.951615, mean_q: 17.547420
Track generation: 1120..1408 -> 288-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1103..1382 -> 279-tiles track
 370199/500000: episode: 398, duration: 73.735s, episode steps: 1000, steps per second:  14, episode reward: 43.885, mean reward:  0.044 [-0.100,  7.094], mean action: 1.924 [0.000, 4.000],  loss: 0.265150, mae: 13.981535, mean_q: 17.595081
Track generation: 1020..1279 -> 259-tiles track
 371199/500000: episode: 399, duration: 73.008s, episode steps: 1000, steps per second:  14, episode reward: 372.868, mean reward:  0.373 [-0.100,  7.652], mean action: 1.909 [0.000, 4.000],  loss: 0.327836, mae: 13.913877, mean_q: 17.518538
Track generation: 1072..1344 -> 272-tiles track
 371919/500000: episode: 400, duration: 52.949s, episode steps: 720, steps per second:  14, episode reward: -138.690, mean reward: -0.193 [-100.000,  7.280], mean action: 1.697 [0.000, 4.000],  loss: 0.285503, mae: 13.921800, mean_q: 17.546089
Track generation: 1217..1525 -> 308-tiles track
 372919/500000: episode: 401, duration: 74.803s, episode steps: 1000, steps per second:  13, episode reward: 369.055, mean reward:  0.369 [-0.100,  6.415], mean action: 1.909 [0.000, 4.000],  loss: 0.266606, mae: 13.909552, mean_q: 17.506841
Track generation: 1111..1400 -> 289-tiles track
 373183/500000: episode: 402, duration: 19.200s, episode steps: 264, steps per second:  14, episode reward: -8.244, mean reward: -0.031 [-100.000,  6.844], mean action: 2.227 [0.000, 4.000],  loss: 0.315489, mae: 13.911983, mean_q: 17.526099
Track generation: 1151..1443 -> 292-tiles track
 374183/500000: episode: 403, duration: 72.662s, episode steps: 1000, steps per second:  14, episode reward: 95.876, mean reward:  0.096 [-0.100, 10.209], mean action: 1.698 [0.000, 4.000],  loss: 0.302989, mae: 13.911875, mean_q: 17.497929
Track generation: 979..1234 -> 255-tiles track
 375183/500000: episode: 404, duration: 74.184s, episode steps: 1000, steps per second:  13, episode reward: 226.772, mean reward:  0.227 [-0.100,  7.774], mean action: 1.503 [0.000, 4.000],  loss: 0.302443, mae: 13.935008, mean_q: 17.511799
Track generation: 1200..1504 -> 304-tiles track
 376183/500000: episode: 405, duration: 74.382s, episode steps: 1000, steps per second:  13, episode reward: -53.795, mean reward: -0.054 [-0.100,  6.501], mean action: 1.860 [0.000, 4.000],  loss: 0.270928, mae: 13.957308, mean_q: 17.559278
Track generation: 1009..1270 -> 261-tiles track
 377183/500000: episode: 406, duration: 72.811s, episode steps: 1000, steps per second:  14, episode reward: 388.462, mean reward:  0.388 [-0.100,  7.592], mean action: 1.894 [0.000, 4.000],  loss: 0.301768, mae: 13.993168, mean_q: 17.618329
Track generation: 998..1261 -> 263-tiles track
 378183/500000: episode: 407, duration: 73.916s, episode steps: 1000, steps per second:  14, episode reward: 151.908, mean reward:  0.152 [-0.100,  7.534], mean action: 1.591 [0.000, 4.000],  loss: 0.288660, mae: 13.901969, mean_q: 17.508792
Track generation: 1123..1408 -> 285-tiles track
 379183/500000: episode: 408, duration: 71.686s, episode steps: 1000, steps per second:  14, episode reward: 135.915, mean reward:  0.136 [-0.100,  6.942], mean action: 1.376 [0.000, 4.000],  loss: 0.303036, mae: 13.933221, mean_q: 17.527364
Track generation: 1196..1499 -> 303-tiles track
 380183/500000: episode: 409, duration: 72.113s, episode steps: 1000, steps per second:  14, episode reward: -73.510, mean reward: -0.074 [-0.100,  6.523], mean action: 1.723 [0.000, 4.000],  loss: 0.295129, mae: 14.020049, mean_q: 17.649335
Track generation: 1000..1258 -> 258-tiles track
 380408/500000: episode: 410, duration: 16.134s, episode steps: 225, steps per second:  14, episode reward: 21.569, mean reward:  0.096 [-100.000,  7.682], mean action: 1.836 [0.000, 4.000],  loss: 0.235516, mae: 13.790370, mean_q: 17.357143
Track generation: 1192..1494 -> 302-tiles track
 381408/500000: episode: 411, duration: 74.565s, episode steps: 1000, steps per second:  13, episode reward: 105.980, mean reward:  0.106 [-0.100,  6.545], mean action: 1.789 [0.000, 4.000],  loss: 0.301989, mae: 13.868869, mean_q: 17.443022
Track generation: 1218..1526 -> 308-tiles track
 382408/500000: episode: 412, duration: 71.873s, episode steps: 1000, steps per second:  14, episode reward: 277.850, mean reward:  0.278 [-0.100,  6.415], mean action: 1.738 [0.000, 4.000],  loss: 0.279095, mae: 13.951096, mean_q: 17.555546
Track generation: 1180..1479 -> 299-tiles track
 383408/500000: episode: 413, duration: 74.278s, episode steps: 1000, steps per second:  13, episode reward: 91.275, mean reward:  0.091 [-0.100,  6.611], mean action: 1.558 [0.000, 4.000],  loss: 0.308685, mae: 13.939037, mean_q: 17.540437
Track generation: 1222..1531 -> 309-tiles track
 384408/500000: episode: 414, duration: 75.125s, episode steps: 1000, steps per second:  13, episode reward: 286.364, mean reward:  0.286 [-0.100,  6.394], mean action: 1.903 [0.000, 4.000],  loss: 0.290980, mae: 13.968231, mean_q: 17.597207
Track generation: 1217..1525 -> 308-tiles track
 385136/500000: episode: 415, duration: 54.965s, episode steps: 728, steps per second:  13, episode reward: 110.688, mean reward:  0.152 [-100.000,  6.415], mean action: 1.904 [0.000, 4.000],  loss: 0.318839, mae: 14.047801, mean_q: 17.685668
Track generation: 1032..1294 -> 262-tiles track
 386136/500000: episode: 416, duration: 75.059s, episode steps: 1000, steps per second:  13, episode reward: 355.939, mean reward:  0.356 [-0.100,  7.563], mean action: 1.442 [0.000, 4.000],  loss: 0.332122, mae: 14.032805, mean_q: 17.660463
Track generation: 1276..1599 -> 323-tiles track
 387136/500000: episode: 417, duration: 75.926s, episode steps: 1000, steps per second:  13, episode reward: 173.292, mean reward:  0.173 [-0.100,  6.111], mean action: 1.751 [0.000, 4.000],  loss: 0.296880, mae: 14.016306, mean_q: 17.653900
Track generation: 1135..1423 -> 288-tiles track
 388136/500000: episode: 418, duration: 75.439s, episode steps: 1000, steps per second:  13, episode reward: 77.700, mean reward:  0.078 [-0.100,  6.869], mean action: 1.804 [0.000, 4.000],  loss: 0.308225, mae: 14.026797, mean_q: 17.626143
Track generation: 1024..1287 -> 263-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1385..1735 -> 350-tiles track
 388934/500000: episode: 419, duration: 61.217s, episode steps: 798, steps per second:  13, episode reward: 115.429, mean reward:  0.145 [-100.000,  5.631], mean action: 1.841 [0.000, 4.000],  loss: 0.255517, mae: 13.950541, mean_q: 17.553147
Track generation: 1036..1307 -> 271-tiles track
 389934/500000: episode: 420, duration: 75.662s, episode steps: 1000, steps per second:  13, episode reward: 70.370, mean reward:  0.070 [-0.100,  7.307], mean action: 1.768 [0.000, 4.000],  loss: 0.340632, mae: 13.993289, mean_q: 17.587512
Track generation: 1096..1374 -> 278-tiles track
 390934/500000: episode: 421, duration: 73.291s, episode steps: 1000, steps per second:  14, episode reward: 325.993, mean reward:  0.326 [-0.100,  7.120], mean action: 1.828 [0.000, 4.000],  loss: 0.274205, mae: 13.729534, mean_q: 17.283064
Track generation: 1164..1459 -> 295-tiles track
 391934/500000: episode: 422, duration: 74.445s, episode steps: 1000, steps per second:  13, episode reward: 134.694, mean reward:  0.135 [-0.100,  6.703], mean action: 1.668 [0.000, 4.000],  loss: 0.300436, mae: 13.903881, mean_q: 17.503792
Track generation: 1299..1627 -> 328-tiles track
 392934/500000: episode: 423, duration: 76.100s, episode steps: 1000, steps per second:  13, episode reward: 377.064, mean reward:  0.377 [-0.100,  6.016], mean action: 1.847 [0.000, 4.000],  loss: 0.332956, mae: 13.873655, mean_q: 17.446239
Track generation: 1223..1533 -> 310-tiles track
 393934/500000: episode: 424, duration: 75.488s, episode steps: 1000, steps per second:  13, episode reward: 230.097, mean reward:  0.230 [-0.100,  6.372], mean action: 1.475 [0.000, 4.000],  loss: 0.305815, mae: 13.937596, mean_q: 17.535748
Track generation: 1226..1546 -> 320-tiles track
 394934/500000: episode: 425, duration: 76.107s, episode steps: 1000, steps per second:  13, episode reward: 78.683, mean reward:  0.079 [-0.100,  6.170], mean action: 1.605 [0.000, 4.000],  loss: 0.335141, mae: 13.951711, mean_q: 17.560958
Track generation: 1083..1364 -> 281-tiles track
 395934/500000: episode: 426, duration: 74.910s, episode steps: 1000, steps per second:  13, episode reward: -0.000, mean reward: -0.000 [-0.100,  7.043], mean action: 1.710 [0.000, 4.000],  loss: 0.333035, mae: 13.860943, mean_q: 17.452720
Track generation: 1277..1600 -> 323-tiles track
 396934/500000: episode: 427, duration: 76.900s, episode steps: 1000, steps per second:  13, episode reward: 148.447, mean reward:  0.148 [-0.100,  6.111], mean action: 1.727 [0.000, 4.000],  loss: 0.293562, mae: 14.097572, mean_q: 17.788743
Track generation: 1095..1373 -> 278-tiles track
 397934/500000: episode: 428, duration: 76.353s, episode steps: 1000, steps per second:  13, episode reward: 246.570, mean reward:  0.247 [-0.100,  7.120], mean action: 1.472 [0.000, 4.000],  loss: 0.325800, mae: 13.925797, mean_q: 17.538178
Track generation: 1188..1489 -> 301-tiles track
 398613/500000: episode: 429, duration: 51.003s, episode steps: 679, steps per second:  13, episode reward: -117.800, mean reward: -0.173 [-100.000,  6.567], mean action: 1.946 [0.000, 4.000],  loss: 0.316477, mae: 13.929394, mean_q: 17.556381
Track generation: 1262..1589 -> 327-tiles track
 399613/500000: episode: 430, duration: 76.912s, episode steps: 1000, steps per second:  13, episode reward: 185.276, mean reward:  0.185 [-0.100,  6.035], mean action: 2.020 [0.000, 4.000],  loss: 0.324997, mae: 14.008500, mean_q: 17.626709
Track generation: 1103..1383 -> 280-tiles track
 400613/500000: episode: 431, duration: 75.569s, episode steps: 1000, steps per second:  13, episode reward: 473.477, mean reward:  0.473 [-0.100,  7.068], mean action: 1.780 [0.000, 4.000],  loss: 0.299380, mae: 13.848017, mean_q: 17.434914
Track generation: 1169..1465 -> 296-tiles track
 401613/500000: episode: 432, duration: 75.886s, episode steps: 1000, steps per second:  13, episode reward: 76.271, mean reward:  0.076 [-0.100,  6.680], mean action: 1.423 [0.000, 4.000],  loss: 0.315961, mae: 13.849755, mean_q: 17.444239
Track generation: 916..1156 -> 240-tiles track
 402613/500000: episode: 433, duration: 71.445s, episode steps: 1000, steps per second:  14, episode reward: 565.272, mean reward:  0.565 [-0.100,  8.268], mean action: 1.802 [0.000, 4.000],  loss: 0.348739, mae: 13.831609, mean_q: 17.412246
Track generation: 1217..1525 -> 308-tiles track
 403535/500000: episode: 434, duration: 68.634s, episode steps: 922, steps per second:  13, episode reward: -126.953, mean reward: -0.138 [-100.000,  6.415], mean action: 1.601 [0.000, 4.000],  loss: 0.357488, mae: 13.770780, mean_q: 17.317368
Track generation: 1207..1513 -> 306-tiles track
 404535/500000: episode: 435, duration: 76.136s, episode steps: 1000, steps per second:  13, episode reward: 352.459, mean reward:  0.352 [-0.100,  6.457], mean action: 1.541 [0.000, 4.000],  loss: 0.335551, mae: 13.810116, mean_q: 17.389219
Track generation: 1014..1274 -> 260-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1228..1539 -> 311-tiles track
 405535/500000: episode: 436, duration: 74.771s, episode steps: 1000, steps per second:  13, episode reward: -22.581, mean reward: -0.023 [-0.100,  6.352], mean action: 1.934 [0.000, 4.000],  loss: 0.342942, mae: 13.774970, mean_q: 17.321855
Track generation: 1231..1543 -> 312-tiles track
 406535/500000: episode: 437, duration: 74.400s, episode steps: 1000, steps per second:  13, episode reward: 424.116, mean reward:  0.424 [-0.100,  6.331], mean action: 1.985 [0.000, 4.000],  loss: 0.348875, mae: 13.783464, mean_q: 17.351548
Track generation: 1251..1568 -> 317-tiles track
 407535/500000: episode: 438, duration: 74.810s, episode steps: 1000, steps per second:  13, episode reward: -55.696, mean reward: -0.056 [-0.100,  6.229], mean action: 1.647 [0.000, 4.000],  loss: 0.327618, mae: 13.741669, mean_q: 17.296297
Track generation: 1219..1528 -> 309-tiles track
 408535/500000: episode: 439, duration: 75.732s, episode steps: 1000, steps per second:  13, episode reward: -38.312, mean reward: -0.038 [-0.100,  6.394], mean action: 1.582 [0.000, 4.000],  loss: 0.335921, mae: 13.801979, mean_q: 17.353661
Track generation: 1207..1513 -> 306-tiles track
 409535/500000: episode: 440, duration: 78.005s, episode steps: 1000, steps per second:  13, episode reward: 201.639, mean reward:  0.202 [-0.100,  6.457], mean action: 1.574 [0.000, 4.000],  loss: 0.324842, mae: 13.800662, mean_q: 17.357368
Track generation: 1267..1588 -> 321-tiles track
 410535/500000: episode: 441, duration: 74.960s, episode steps: 1000, steps per second:  13, episode reward: 262.500, mean reward:  0.262 [-0.100,  6.150], mean action: 1.445 [0.000, 4.000],  loss: 0.349908, mae: 13.831045, mean_q: 17.414563
Track generation: 1114..1416 -> 302-tiles track
 411535/500000: episode: 442, duration: 76.401s, episode steps: 1000, steps per second:  13, episode reward: 345.183, mean reward:  0.345 [-0.100,  6.545], mean action: 1.705 [0.000, 4.000],  loss: 0.375592, mae: 13.823369, mean_q: 17.414341
Track generation: 1121..1406 -> 285-tiles track
 412510/500000: episode: 443, duration: 73.965s, episode steps: 975, steps per second:  13, episode reward: 98.375, mean reward:  0.101 [-100.000,  6.942], mean action: 1.837 [0.000, 4.000],  loss: 0.367853, mae: 13.751936, mean_q: 17.324035
Track generation: 1107..1388 -> 281-tiles track
 413510/500000: episode: 444, duration: 75.640s, episode steps: 1000, steps per second:  13, episode reward: 225.000, mean reward:  0.225 [-0.100,  7.043], mean action: 1.833 [0.000, 4.000],  loss: 0.324448, mae: 13.687674, mean_q: 17.205640
Track generation: 1321..1666 -> 345-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1080..1361 -> 281-tiles track
 414510/500000: episode: 445, duration: 75.216s, episode steps: 1000, steps per second:  13, episode reward: 53.571, mean reward:  0.054 [-0.100,  7.043], mean action: 1.707 [0.000, 4.000],  loss: 0.312115, mae: 13.694504, mean_q: 17.231485
Track generation: 1136..1424 -> 288-tiles track
 415510/500000: episode: 446, duration: 78.243s, episode steps: 1000, steps per second:  13, episode reward: 269.338, mean reward:  0.269 [-0.100,  6.869], mean action: 2.081 [0.000, 4.000],  loss: 0.373388, mae: 13.612891, mean_q: 17.102943
Track generation: 1008..1264 -> 256-tiles track
 416510/500000: episode: 447, duration: 76.653s, episode steps: 1000, steps per second:  13, episode reward: 252.941, mean reward:  0.253 [-0.100,  7.743], mean action: 1.597 [0.000, 4.000],  loss: 0.329695, mae: 13.734300, mean_q: 17.298345
Track generation: 1128..1414 -> 286-tiles track
 417510/500000: episode: 448, duration: 76.057s, episode steps: 1000, steps per second:  13, episode reward: 250.877, mean reward:  0.251 [-0.100,  6.918], mean action: 1.794 [0.000, 4.000],  loss: 0.328982, mae: 13.732678, mean_q: 17.292106
Track generation: 1135..1423 -> 288-tiles track
 418510/500000: episode: 449, duration: 75.263s, episode steps: 1000, steps per second:  13, episode reward: 49.826, mean reward:  0.050 [-0.100,  6.869], mean action: 1.321 [0.000, 4.000],  loss: 0.345626, mae: 13.784531, mean_q: 17.365011
Track generation: 1102..1387 -> 285-tiles track
 419510/500000: episode: 450, duration: 75.655s, episode steps: 1000, steps per second:  13, episode reward: 223.944, mean reward:  0.224 [-0.100,  6.942], mean action: 1.573 [0.000, 4.000],  loss: 0.332072, mae: 13.792797, mean_q: 17.370059
Track generation: 1288..1614 -> 326-tiles track
 420510/500000: episode: 451, duration: 77.275s, episode steps: 1000, steps per second:  13, episode reward: 115.385, mean reward:  0.115 [-0.100,  6.054], mean action: 1.351 [0.000, 4.000],  loss: 0.345423, mae: 13.721806, mean_q: 17.278010
Track generation: 1191..1501 -> 310-tiles track
 421510/500000: episode: 452, duration: 78.382s, episode steps: 1000, steps per second:  13, episode reward: 294.822, mean reward:  0.295 [-0.100,  6.372], mean action: 1.468 [0.000, 4.000],  loss: 0.385651, mae: 13.792900, mean_q: 17.339739
Track generation: 1147..1438 -> 291-tiles track
 422510/500000: episode: 453, duration: 75.983s, episode steps: 1000, steps per second:  13, episode reward: -6.897, mean reward: -0.007 [-0.100,  6.797], mean action: 1.787 [0.000, 4.000],  loss: 0.364610, mae: 13.803854, mean_q: 17.390967
Track generation: 1171..1468 -> 297-tiles track
 423510/500000: episode: 454, duration: 76.367s, episode steps: 1000, steps per second:  13, episode reward: -35.811, mean reward: -0.036 [-0.100,  6.657], mean action: 1.751 [0.000, 4.000],  loss: 0.397589, mae: 13.788678, mean_q: 17.331051
Track generation: 1130..1417 -> 287-tiles track
 424510/500000: episode: 455, duration: 77.719s, episode steps: 1000, steps per second:  13, episode reward: 183.217, mean reward:  0.183 [-0.100,  6.893], mean action: 1.660 [0.000, 4.000],  loss: 0.373631, mae: 13.840553, mean_q: 17.402411
Track generation: 1221..1530 -> 309-tiles track
 425510/500000: episode: 456, duration: 77.425s, episode steps: 1000, steps per second:  13, episode reward: 497.403, mean reward:  0.497 [-0.100,  6.394], mean action: 1.815 [0.000, 4.000],  loss: 0.354779, mae: 13.860965, mean_q: 17.428191
Track generation: 1231..1543 -> 312-tiles track
 426510/500000: episode: 457, duration: 77.285s, episode steps: 1000, steps per second:  13, episode reward: 530.225, mean reward:  0.530 [-0.100,  6.331], mean action: 1.907 [0.000, 4.000],  loss: 0.384808, mae: 13.919650, mean_q: 17.517243
Track generation: 1060..1329 -> 269-tiles track
 427510/500000: episode: 458, duration: 77.113s, episode steps: 1000, steps per second:  13, episode reward: 802.985, mean reward:  0.803 [-0.100,  7.363], mean action: 1.705 [0.000, 4.000],  loss: 0.345615, mae: 13.889527, mean_q: 17.476026
Track generation: 972..1223 -> 251-tiles track
 428484/500000: episode: 459, duration: 75.009s, episode steps: 974, steps per second:  13, episode reward: 470.700, mean reward:  0.483 [-100.000,  7.900], mean action: 1.958 [0.000, 4.000],  loss: 0.326950, mae: 13.848723, mean_q: 17.434947
Track generation: 1208..1514 -> 306-tiles track
 429484/500000: episode: 460, duration: 78.101s, episode steps: 1000, steps per second:  13, episode reward: 372.131, mean reward:  0.372 [-0.100,  6.457], mean action: 1.940 [0.000, 4.000],  loss: 0.378170, mae: 13.974198, mean_q: 17.575798
Track generation: 944..1184 -> 240-tiles track
 430484/500000: episode: 461, duration: 76.681s, episode steps: 1000, steps per second:  13, episode reward: 862.343, mean reward:  0.862 [-0.100,  8.268], mean action: 1.772 [0.000, 4.000],  loss: 0.361529, mae: 13.880891, mean_q: 17.461881
Track generation: 1060..1338 -> 278-tiles track
 431484/500000: episode: 462, duration: 79.502s, episode steps: 1000, steps per second:  13, episode reward: 777.256, mean reward:  0.777 [-0.100,  7.120], mean action: 1.272 [0.000, 4.000],  loss: 0.380096, mae: 13.718817, mean_q: 17.265978
Track generation: 1113..1395 -> 282-tiles track
 432484/500000: episode: 463, duration: 77.310s, episode steps: 1000, steps per second:  13, episode reward: 227.402, mean reward:  0.227 [-0.100,  7.017], mean action: 1.556 [0.000, 4.000],  loss: 0.355126, mae: 13.736384, mean_q: 17.294628
Track generation: 1078..1352 -> 274-tiles track
 433484/500000: episode: 464, duration: 78.204s, episode steps: 1000, steps per second:  13, episode reward: 548.352, mean reward:  0.548 [-0.100,  7.226], mean action: 1.810 [0.000, 4.000],  loss: 0.412796, mae: 13.897116, mean_q: 17.482709
Track generation: 1076..1353 -> 277-tiles track
 433748/500000: episode: 465, duration: 21.200s, episode steps: 264, steps per second:  12, episode reward:  0.512, mean reward:  0.002 [-100.000,  7.146], mean action: 1.648 [0.000, 4.000],  loss: 0.402775, mae: 13.889108, mean_q: 17.502073
Track generation: 1023..1283 -> 260-tiles track
 434748/500000: episode: 466, duration: 77.775s, episode steps: 1000, steps per second:  13, episode reward: 297.683, mean reward:  0.298 [-0.100,  7.622], mean action: 1.907 [0.000, 4.000],  loss: 0.366965, mae: 13.849619, mean_q: 17.427955
Track generation: 1255..1573 -> 318-tiles track
 435748/500000: episode: 467, duration: 78.100s, episode steps: 1000, steps per second:  13, episode reward: 29.338, mean reward:  0.029 [-0.100,  6.209], mean action: 1.670 [0.000, 4.000],  loss: 0.379057, mae: 13.806993, mean_q: 17.365190
Track generation: 1276..1599 -> 323-tiles track
 436748/500000: episode: 468, duration: 78.934s, episode steps: 1000, steps per second:  13, episode reward: 55.280, mean reward:  0.055 [-0.100,  6.111], mean action: 1.595 [0.000, 4.000],  loss: 0.389503, mae: 13.964361, mean_q: 17.569447
Track generation: 1303..1633 -> 330-tiles track
 437748/500000: episode: 469, duration: 78.662s, episode steps: 1000, steps per second:  13, episode reward: 334.650, mean reward:  0.335 [-0.100,  5.979], mean action: 1.415 [0.000, 4.000],  loss: 0.395508, mae: 14.017950, mean_q: 17.675802
Track generation: 1167..1463 -> 296-tiles track
 438748/500000: episode: 470, duration: 78.443s, episode steps: 1000, steps per second:  13, episode reward: 201.695, mean reward:  0.202 [-0.100,  6.680], mean action: 1.706 [0.000, 4.000],  loss: 0.363585, mae: 13.950602, mean_q: 17.568015
Track generation: 1240..1554 -> 314-tiles track
 439748/500000: episode: 471, duration: 78.555s, episode steps: 1000, steps per second:  13, episode reward: 232.268, mean reward:  0.232 [-0.100,  6.290], mean action: 2.019 [0.000, 4.000],  loss: 0.364452, mae: 14.057880, mean_q: 17.703726
Track generation: 1224..1534 -> 310-tiles track
 440748/500000: episode: 472, duration: 78.697s, episode steps: 1000, steps per second:  13, episode reward: 210.680, mean reward:  0.211 [-0.100,  6.372], mean action: 1.249 [0.000, 4.000],  loss: 0.416281, mae: 13.781475, mean_q: 17.346367
Track generation: 1108..1399 -> 291-tiles track
 441748/500000: episode: 473, duration: 78.620s, episode steps: 1000, steps per second:  13, episode reward: 110.345, mean reward:  0.110 [-0.100,  6.797], mean action: 1.744 [0.000, 4.000],  loss: 0.394606, mae: 13.786179, mean_q: 17.345213
Track generation: 1116..1404 -> 288-tiles track
 442748/500000: episode: 474, duration: 78.152s, episode steps: 1000, steps per second:  13, episode reward: -33.798, mean reward: -0.034 [-0.100,  6.869], mean action: 1.414 [0.000, 4.000],  loss: 0.386368, mae: 13.811474, mean_q: 17.371580
Track generation: 1251..1568 -> 317-tiles track
 443748/500000: episode: 475, duration: 79.699s, episode steps: 1000, steps per second:  13, episode reward: 276.582, mean reward:  0.277 [-0.100,  6.229], mean action: 1.935 [0.000, 4.000],  loss: 0.431948, mae: 13.876929, mean_q: 17.473663
Track generation: 967..1213 -> 246-tiles track
 444748/500000: episode: 476, duration: 77.924s, episode steps: 1000, steps per second:  13, episode reward: 622.449, mean reward:  0.622 [-0.100,  8.063], mean action: 1.875 [0.000, 4.000],  loss: 0.381823, mae: 13.764229, mean_q: 17.344047
Track generation: 1414..1771 -> 357-tiles track
 445748/500000: episode: 477, duration: 79.456s, episode steps: 1000, steps per second:  13, episode reward: 133.146, mean reward:  0.133 [-0.100,  5.518], mean action: 1.472 [0.000, 4.000],  loss: 0.421267, mae: 13.880545, mean_q: 17.468175
Track generation: 1188..1489 -> 301-tiles track
 446421/500000: episode: 478, duration: 53.684s, episode steps: 673, steps per second:  13, episode reward: -117.200, mean reward: -0.174 [-100.000,  6.567], mean action: 1.281 [0.000, 4.000],  loss: 0.431248, mae: 13.836277, mean_q: 17.440660
Track generation: 1079..1359 -> 280-tiles track
 446765/500000: episode: 479, duration: 27.033s, episode steps: 344, steps per second:  13, episode reward: -19.605, mean reward: -0.057 [-100.000,  7.068], mean action: 1.625 [0.000, 4.000],  loss: 0.438772, mae: 13.735958, mean_q: 17.333973
Track generation: 1264..1584 -> 320-tiles track
 447765/500000: episode: 480, duration: 80.584s, episode steps: 1000, steps per second:  12, episode reward: 238.558, mean reward:  0.239 [-0.100,  6.170], mean action: 1.857 [0.000, 4.000],  loss: 0.398825, mae: 13.877587, mean_q: 17.491654
Track generation: 1140..1429 -> 289-tiles track
 448765/500000: episode: 481, duration: 75.498s, episode steps: 1000, steps per second:  13, episode reward: 275.000, mean reward:  0.275 [-0.100,  6.844], mean action: 1.408 [0.000, 4.000],  loss: 0.400323, mae: 13.860289, mean_q: 17.427880
Track generation: 1170..1467 -> 297-tiles track
 449765/500000: episode: 482, duration: 77.765s, episode steps: 1000, steps per second:  13, episode reward: 619.595, mean reward:  0.620 [-0.100,  6.657], mean action: 1.476 [0.000, 4.000],  loss: 0.391967, mae: 13.909588, mean_q: 17.505022
Track generation: 1115..1398 -> 283-tiles track
 450765/500000: episode: 483, duration: 79.190s, episode steps: 1000, steps per second:  13, episode reward: 368.085, mean reward:  0.368 [-0.100,  6.992], mean action: 1.627 [0.000, 4.000],  loss: 0.392454, mae: 13.819319, mean_q: 17.403615
Track generation: 1195..1498 -> 303-tiles track
 451765/500000: episode: 484, duration: 79.586s, episode steps: 1000, steps per second:  13, episode reward: 214.570, mean reward:  0.215 [-0.100,  6.523], mean action: 1.565 [0.000, 4.000],  loss: 0.478647, mae: 14.056087, mean_q: 17.665259
Track generation: 1120..1411 -> 291-tiles track
 452765/500000: episode: 485, duration: 78.466s, episode steps: 1000, steps per second:  13, episode reward: 82.759, mean reward:  0.083 [-0.100,  6.797], mean action: 2.338 [0.000, 4.000],  loss: 0.414022, mae: 13.998192, mean_q: 17.613474
Track generation: 1180..1479 -> 299-tiles track
 453765/500000: episode: 486, duration: 78.801s, episode steps: 1000, steps per second:  13, episode reward: 198.658, mean reward:  0.199 [-0.100,  6.611], mean action: 1.866 [0.000, 4.000],  loss: 0.396091, mae: 13.911690, mean_q: 17.504317
Track generation: 1075..1354 -> 279-tiles track
 454765/500000: episode: 487, duration: 80.024s, episode steps: 1000, steps per second:  12, episode reward: 69.065, mean reward:  0.069 [-0.100,  7.094], mean action: 1.954 [0.000, 4.000],  loss: 0.412148, mae: 13.937871, mean_q: 17.545693
Track generation: 1089..1365 -> 276-tiles track
 455765/500000: episode: 488, duration: 78.860s, episode steps: 1000, steps per second:  13, episode reward: 634.545, mean reward:  0.635 [-0.100,  7.173], mean action: 1.548 [0.000, 4.000],  loss: 0.412811, mae: 13.961270, mean_q: 17.587148
Track generation: 1107..1388 -> 281-tiles track
 456341/500000: episode: 489, duration: 44.724s, episode steps: 576, steps per second:  13, episode reward: 185.357, mean reward:  0.322 [-100.000,  7.043], mean action: 1.693 [0.000, 4.000],  loss: 0.415948, mae: 13.887632, mean_q: 17.517379
Track generation: 1092..1369 -> 277-tiles track
 457341/500000: episode: 490, duration: 78.177s, episode steps: 1000, steps per second:  13, episode reward: 313.043, mean reward:  0.313 [-0.100,  7.146], mean action: 1.764 [0.000, 4.000],  loss: 0.407053, mae: 13.895158, mean_q: 17.513197
Track generation: 1111..1393 -> 282-tiles track
 458341/500000: episode: 491, duration: 78.564s, episode steps: 1000, steps per second:  13, episode reward: 334.164, mean reward:  0.334 [-0.100,  7.017], mean action: 1.837 [0.000, 4.000],  loss: 0.420296, mae: 14.015091, mean_q: 17.650401
Track generation: 1138..1432 -> 294-tiles track
 459155/500000: episode: 492, duration: 64.862s, episode steps: 814, steps per second:  13, episode reward: -48.194, mean reward: -0.059 [-100.000,  6.726], mean action: 1.972 [0.000, 4.000],  loss: 0.411763, mae: 13.919780, mean_q: 17.531740
Track generation: 1252..1569 -> 317-tiles track
 460155/500000: episode: 493, duration: 79.219s, episode steps: 1000, steps per second:  13, episode reward: 219.620, mean reward:  0.220 [-0.100,  6.229], mean action: 1.765 [0.000, 4.000],  loss: 0.397292, mae: 14.004708, mean_q: 17.638545
Track generation: 1176..1474 -> 298-tiles track
 461155/500000: episode: 494, duration: 77.518s, episode steps: 1000, steps per second:  13, episode reward: 172.727, mean reward:  0.173 [-0.100,  6.634], mean action: 1.884 [0.000, 4.000],  loss: 0.399573, mae: 14.008471, mean_q: 17.642241
Track generation: 1013..1271 -> 258-tiles track
 462155/500000: episode: 495, duration: 77.974s, episode steps: 1000, steps per second:  13, episode reward: 779.377, mean reward:  0.779 [-0.100,  7.682], mean action: 1.753 [0.000, 4.000],  loss: 0.406695, mae: 14.077621, mean_q: 17.727740
Track generation: 1225..1537 -> 312-tiles track
 463155/500000: episode: 496, duration: 80.737s, episode steps: 1000, steps per second:  12, episode reward: 99.357, mean reward:  0.099 [-0.100,  6.331], mean action: 1.430 [0.000, 4.000],  loss: 0.376538, mae: 14.093004, mean_q: 17.771550
Track generation: 1171..1473 -> 302-tiles track
 464155/500000: episode: 497, duration: 80.001s, episode steps: 1000, steps per second:  12, episode reward: 355.150, mean reward:  0.355 [-0.100,  6.545], mean action: 1.922 [0.000, 4.000],  loss: 0.374506, mae: 14.027497, mean_q: 17.669141
Track generation: 1036..1299 -> 263-tiles track
 465155/500000: episode: 498, duration: 79.590s, episode steps: 1000, steps per second:  13, episode reward: 667.176, mean reward:  0.667 [-0.100,  7.534], mean action: 1.852 [0.000, 4.000],  loss: 0.389067, mae: 14.093715, mean_q: 17.770942
Track generation: 1078..1351 -> 273-tiles track
 466155/500000: episode: 499, duration: 80.353s, episode steps: 1000, steps per second:  12, episode reward: 275.000, mean reward:  0.275 [-0.100,  7.253], mean action: 1.707 [0.000, 4.000],  loss: 0.404163, mae: 14.059382, mean_q: 17.732845
Track generation: 1082..1361 -> 279-tiles track
 466702/500000: episode: 500, duration: 43.454s, episode steps: 547, steps per second:  13, episode reward: -25.104, mean reward: -0.046 [-100.000,  7.094], mean action: 1.598 [0.000, 4.000],  loss: 0.463082, mae: 14.043861, mean_q: 17.694611
Track generation: 1044..1318 -> 274-tiles track
 467702/500000: episode: 501, duration: 79.058s, episode steps: 1000, steps per second:  13, episode reward: 211.355, mean reward:  0.211 [-0.100, 10.889], mean action: 2.140 [0.000, 4.000],  loss: 0.400312, mae: 14.161734, mean_q: 17.866440
Track generation: 1131..1418 -> 287-tiles track
 468702/500000: episode: 502, duration: 78.655s, episode steps: 1000, steps per second:  13, episode reward: 655.245, mean reward:  0.655 [-0.100,  6.893], mean action: 1.663 [0.000, 4.000],  loss: 0.435844, mae: 14.130852, mean_q: 17.784310
Track generation: 1057..1325 -> 268-tiles track
 469702/500000: episode: 503, duration: 78.077s, episode steps: 1000, steps per second:  13, episode reward: -28.839, mean reward: -0.029 [-0.100,  7.391], mean action: 2.074 [0.000, 4.000],  loss: 0.423101, mae: 14.228036, mean_q: 17.930464
Track generation: 1158..1453 -> 295-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 981..1233 -> 252-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1062..1338 -> 276-tiles track
 470702/500000: episode: 504, duration: 77.639s, episode steps: 1000, steps per second:  13, episode reward: -67.273, mean reward: -0.067 [-0.100,  7.173], mean action: 1.989 [0.000, 4.000],  loss: 0.422362, mae: 14.138325, mean_q: 17.833106
Track generation: 1135..1423 -> 288-tiles track
 471702/500000: episode: 505, duration: 79.440s, episode steps: 1000, steps per second:  13, episode reward: 126.481, mean reward:  0.126 [-0.100,  6.869], mean action: 1.466 [0.000, 4.000],  loss: 0.402383, mae: 14.046027, mean_q: 17.710043
Track generation: 1290..1626 -> 336-tiles track
 472702/500000: episode: 506, duration: 80.032s, episode steps: 1000, steps per second:  12, episode reward: 40.299, mean reward:  0.040 [-0.100,  5.870], mean action: 1.508 [0.000, 4.000],  loss: 0.447305, mae: 14.256891, mean_q: 17.943992
Track generation: 1103..1383 -> 280-tiles track
 473702/500000: episode: 507, duration: 79.466s, episode steps: 1000, steps per second:  13, episode reward: 46.953, mean reward:  0.047 [-0.100,  7.068], mean action: 1.506 [0.000, 4.000],  loss: 0.414604, mae: 14.143317, mean_q: 17.810827
Track generation: 1208..1517 -> 309-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 1036..1303 -> 267-tiles track
 474702/500000: episode: 508, duration: 78.839s, episode steps: 1000, steps per second:  13, episode reward: 181.955, mean reward:  0.182 [-0.100,  7.419], mean action: 1.908 [0.000, 4.000],  loss: 0.420380, mae: 13.997607, mean_q: 17.624208
Track generation: 1103..1383 -> 280-tiles track
 475702/500000: episode: 509, duration: 78.086s, episode steps: 1000, steps per second:  13, episode reward: 301.434, mean reward:  0.301 [-0.100,  7.068], mean action: 1.848 [0.000, 4.000],  loss: 0.430551, mae: 13.996417, mean_q: 17.627362
Track generation: 1140..1429 -> 289-tiles track
 476702/500000: episode: 510, duration: 79.465s, episode steps: 1000, steps per second:  13, episode reward: 18.056, mean reward:  0.018 [-0.100,  6.844], mean action: 1.786 [0.000, 4.000],  loss: 0.428687, mae: 14.066154, mean_q: 17.707573
Track generation: 1188..1489 -> 301-tiles track
 477702/500000: episode: 511, duration: 79.547s, episode steps: 1000, steps per second:  13, episode reward: 623.333, mean reward:  0.623 [-0.100,  6.567], mean action: 1.654 [0.000, 4.000],  loss: 0.464649, mae: 14.231315, mean_q: 17.892600
Track generation: 1153..1451 -> 298-tiles track
 477903/500000: episode: 512, duration: 16.176s, episode steps: 201, steps per second:  12, episode reward:  7.946, mean reward:  0.040 [-100.000,  6.634], mean action: 2.617 [0.000, 4.000],  loss: 0.571542, mae: 14.103293, mean_q: 17.670562
Track generation: 1135..1423 -> 288-tiles track
 478903/500000: episode: 513, duration: 80.055s, episode steps: 1000, steps per second:  12, episode reward: 384.321, mean reward:  0.384 [-0.100,  6.869], mean action: 1.694 [0.000, 4.000],  loss: 0.451105, mae: 14.314536, mean_q: 18.009207
Track generation: 1106..1394 -> 288-tiles track
 479528/500000: episode: 514, duration: 50.776s, episode steps: 625, steps per second:  12, episode reward: -61.355, mean reward: -0.098 [-100.000,  6.869], mean action: 2.293 [0.000, 4.000],  loss: 0.441624, mae: 14.113757, mean_q: 17.757465
Track generation: 1080..1359 -> 279-tiles track
 480528/500000: episode: 515, duration: 79.600s, episode steps: 1000, steps per second:  13, episode reward: 360.432, mean reward:  0.360 [-0.100,  7.094], mean action: 1.427 [0.000, 4.000],  loss: 0.434479, mae: 14.217393, mean_q: 17.920380
Track generation: 1184..1484 -> 300-tiles track
 481121/500000: episode: 516, duration: 47.114s, episode steps: 593, steps per second:  13, episode reward: -82.277, mean reward: -0.139 [-100.000,  6.589], mean action: 1.691 [0.000, 4.000],  loss: 0.448493, mae: 14.290602, mean_q: 17.990291
Track generation: 1177..1475 -> 298-tiles track
 482121/500000: episode: 517, duration: 80.111s, episode steps: 1000, steps per second:  12, episode reward: 293.939, mean reward:  0.294 [-0.100,  6.634], mean action: 2.133 [0.000, 4.000],  loss: 0.410087, mae: 14.290744, mean_q: 18.021523
Track generation: 1080..1354 -> 274-tiles track
 483121/500000: episode: 518, duration: 78.535s, episode steps: 1000, steps per second:  13, episode reward: 204.029, mean reward:  0.204 [-0.100,  7.226], mean action: 1.363 [0.000, 4.000],  loss: 0.454110, mae: 14.362998, mean_q: 18.115603
Track generation: 1167..1463 -> 296-tiles track
 484121/500000: episode: 519, duration: 79.121s, episode steps: 1000, steps per second:  13, episode reward: 313.559, mean reward:  0.314 [-0.100,  6.680], mean action: 1.443 [0.000, 4.000],  loss: 0.487913, mae: 14.356112, mean_q: 18.115166
Track generation: 952..1194 -> 242-tiles track
 485121/500000: episode: 520, duration: 77.010s, episode steps: 1000, steps per second:  13, episode reward: 402.075, mean reward:  0.402 [-0.100,  8.199], mean action: 1.966 [0.000, 4.000],  loss: 0.459437, mae: 14.340282, mean_q: 18.105324
Track generation: 1164..1459 -> 295-tiles track
 486121/500000: episode: 521, duration: 78.702s, episode steps: 1000, steps per second:  13, episode reward: 76.871, mean reward:  0.077 [-0.100,  6.703], mean action: 2.202 [0.000, 4.000],  loss: 0.414705, mae: 14.307776, mean_q: 18.059027
Track generation: 1194..1496 -> 302-tiles track
 487121/500000: episode: 522, duration: 79.538s, episode steps: 1000, steps per second:  13, episode reward: 155.814, mean reward:  0.156 [-0.100,  6.545], mean action: 1.452 [0.000, 4.000],  loss: 0.448641, mae: 14.441463, mean_q: 18.198344
Track generation: 1209..1526 -> 317-tiles track
 488121/500000: episode: 523, duration: 81.071s, episode steps: 1000, steps per second:  12, episode reward:  7.595, mean reward:  0.008 [-0.100,  6.229], mean action: 1.955 [0.000, 4.000],  loss: 0.452354, mae: 14.444818, mean_q: 18.204729
Track generation: 1034..1303 -> 269-tiles track
 489121/500000: episode: 524, duration: 79.323s, episode steps: 1000, steps per second:  13, episode reward: 64.179, mean reward:  0.064 [-0.100,  7.363], mean action: 1.576 [0.000, 4.000],  loss: 0.452537, mae: 14.344291, mean_q: 18.090018
Track generation: 1240..1554 -> 314-tiles track
 490121/500000: episode: 525, duration: 80.653s, episode steps: 1000, steps per second:  12, episode reward: 91.693, mean reward:  0.092 [-0.100,  6.290], mean action: 1.569 [0.000, 4.000],  loss: 0.443465, mae: 14.362601, mean_q: 18.132798
Track generation: 1180..1479 -> 299-tiles track
 491121/500000: episode: 526, duration: 79.872s, episode steps: 1000, steps per second:  13, episode reward: 138.255, mean reward:  0.138 [-0.100,  6.611], mean action: 1.366 [0.000, 4.000],  loss: 0.440894, mae: 14.347839, mean_q: 18.105115
Track generation: 1171..1468 -> 297-tiles track
 492121/500000: episode: 527, duration: 81.428s, episode steps: 1000, steps per second:  12, episode reward: 234.459, mean reward:  0.234 [-0.100,  6.657], mean action: 1.848 [0.000, 4.000],  loss: 0.479653, mae: 14.364057, mean_q: 18.107272
Track generation: 1136..1424 -> 288-tiles track
 493121/500000: episode: 528, duration: 81.267s, episode steps: 1000, steps per second:  12, episode reward: 387.805, mean reward:  0.388 [-0.100,  6.869], mean action: 1.427 [0.000, 4.000],  loss: 0.450827, mae: 14.240849, mean_q: 17.977422
Track generation: 1139..1428 -> 289-tiles track
 494121/500000: episode: 529, duration: 78.459s, episode steps: 1000, steps per second:  13, episode reward: -79.167, mean reward: -0.079 [-0.100,  6.844], mean action: 1.510 [0.000, 4.000],  loss: 0.507057, mae: 14.385753, mean_q: 18.139813
Track generation: 1211..1518 -> 307-tiles track
 495034/500000: episode: 530, duration: 71.792s, episode steps: 913, steps per second:  13, episode reward: -132.376, mean reward: -0.145 [-100.000,  6.436], mean action: 1.717 [0.000, 4.000],  loss: 0.475984, mae: 14.215512, mean_q: 17.906939
Track generation: 1158..1452 -> 294-tiles track
 496034/500000: episode: 531, duration: 79.265s, episode steps: 1000, steps per second:  13, episode reward: 70.648, mean reward:  0.071 [-0.100,  6.726], mean action: 2.209 [0.000, 4.000],  loss: 0.472072, mae: 14.256681, mean_q: 17.938425
Track generation: 1057..1325 -> 268-tiles track
 497034/500000: episode: 532, duration: 77.873s, episode steps: 1000, steps per second:  13, episode reward: 360.674, mean reward:  0.361 [-0.100,  7.391], mean action: 1.287 [0.000, 4.000],  loss: 0.475527, mae: 14.269449, mean_q: 17.966878
Track generation: 1146..1442 -> 296-tiles track
 498034/500000: episode: 533, duration: 79.908s, episode steps: 1000, steps per second:  13, episode reward: 161.017, mean reward:  0.161 [-0.100,  6.680], mean action: 1.575 [0.000, 4.000],  loss: 0.467429, mae: 14.229742, mean_q: 17.913711
Track generation: 1028..1289 -> 261-tiles track
 499034/500000: episode: 534, duration: 78.720s, episode steps: 1000, steps per second:  13, episode reward: 380.769, mean reward:  0.381 [-0.100,  7.592], mean action: 2.029 [0.000, 4.000],  loss: 0.441591, mae: 14.295693, mean_q: 18.009721
Track generation: 1188..1497 -> 309-tiles track
retry to generate track (normal if there are not many of this messages)
Track generation: 934..1173 -> 239-tiles track
done, took 30568.895 seconds
Testing for 5 episodes ...
Track generation: 1043..1308 -> 265-tiles track
Episode 1: reward: -24.242, steps: 1000
Track generation: 1108..1397 -> 289-tiles track
Episode 2: reward: 611.806, steps: 1000
Track generation: 1031..1293 -> 262-tiles track
Episode 3: reward: -11.877, steps: 1000
Track generation: 1169..1465 -> 296-tiles track
Episode 4: reward: 391.525, steps: 1000
Track generation: 1162..1461 -> 299-tiles track
Episode 5: reward: 497.315, steps: 1000
(.venv) Anastasias-MacBook-Pro:tensorflow_project anastasia$ python utils/karas_model.py --mode=test --evaluation_episodes=2
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: WARN: Box bound precision lowered by casting to float32
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
[[ 0.   0.   0. ]
 [-1.   0.   0. ]
 [ 1.   0.   0. ]
 [ 0.   1.   0. ]
 [ 0.   0.   0.8]]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
observation_input (InputLayer)  [(None, 10, 97, 96)] 0                                            
__________________________________________________________________________________________________
permute (Permute)               (None, 97, 96, 10)   0           observation_input[0][0]          
__________________________________________________________________________________________________
cropping2d (Cropping2D)         (None, 96, 96, 10)   0           permute[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 23, 23, 32)   20512       cropping2d[0][0]                 
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 10, 10, 32)   16416       conv2d[0][0]                     
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 1, 8, 10)     0           permute[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 8, 8, 32)     9248        conv2d_1[0][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1, 8, 64)     704         cropping2d_1[0][0]               
__________________________________________________________________________________________________
flatten (Flatten)               (None, 2048)         0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1, 8, 32)     2080        dense_1[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          1049088     flatten[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 256)          0           dense_2[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 768)          0           dense[0][0]                      
                                                                 flatten_1[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 256)          196864      concatenate[0][0]                
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 5)            1285        dense_3[0][0]                    
==================================================================================================
Total params: 1,296,197
Trainable params: 1,296,197
Non-trainable params: 0
__________________________________________________________________________________________________
None
2020-03-08 09:41:46.557543: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Traceback (most recent call last):
  File "utils/karas_model.py", line 388, in <module>
    agent.load_weights(weights_filename)
  File "/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/rl/agents/dqn.py", line 209, in load_weights
    self.update_target_model_hard()
  File "/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/rl/agents/dqn.py", line 222, in update_target_model_hard
    self.target_model.set_weights(self.model.get_weights())
  File "/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 1166, in set_weights
    'provided weight shape ' + str(w.shape))
ValueError: Layer weight shape (10, 64) not compatible with provided weight shape (10, 128)
(.venv) Anastasias-MacBook-Pro:tensorflow_project anastasia$ python utils/karas_model.py --mode=test --evaluation_episodes=4
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/Users/anastasia/Documents/code/tensorflow_project/.venv/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: WARN: Box bound precision lowered by casting to float32
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
[[ 0.   0.   0. ]
 [-1.   0.   0. ]
 [ 1.   0.   0. ]
 [ 0.   1.   0. ]
 [ 0.   0.   0.8]]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
observation_input (InputLayer)  [(None, 10, 97, 96)] 0                                            
__________________________________________________________________________________________________
permute (Permute)               (None, 97, 96, 10)   0           observation_input[0][0]          
__________________________________________________________________________________________________
cropping2d (Cropping2D)         (None, 96, 96, 10)   0           permute[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 23, 23, 32)   20512       cropping2d[0][0]                 
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 10, 10, 32)   16416       conv2d[0][0]                     
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 1, 96, 10)    0           permute[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 8, 8, 32)     9248        conv2d_1[0][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1, 96, 64)    704         cropping2d_1[0][0]               
__________________________________________________________________________________________________
flatten (Flatten)               (None, 2048)         0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1, 96, 32)    2080        dense_1[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          1049088     flatten[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3072)         0           dense_2[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 3584)         0           dense[0][0]                      
                                                                 flatten_1[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 256)          917760      concatenate[0][0]                
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 5)            1285        dense_3[0][0]                    
==================================================================================================
Total params: 2,017,093
Trainable params: 2,017,093
Non-trainable params: 0
_____________________________________________________________________________________________
